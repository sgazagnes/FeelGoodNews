{
  "personality": null,
  "timestamp": "2026-01-15T04:56:35.733162",
  "category": "Technology",
  "news_summary": "Recent advancements showcase breakthroughs in understanding cellular evolution, innovative stretchable OLED technology, novel particle interaction observations, and cutting-edge 3D-printed microactuators.",
  "news_summary_fr": "Les avancées récentes mettent en évidence des percées dans la compréhension de l'évolution cellulaire, une technologie OLED extensible innovante, de nouvelles observations sur les interactions entre particules et des microactionneurs imprimés en 3D à la pointe de la technologie.",
  "news_summary_es": "Los últimos avances muestran avances revolucionarios en la comprensión de la evolución celular, la innovadora tecnología OLED elástica, nuevas observaciones sobre la interacción de partículas y microactuadores de vanguardia impresos en 3D.",
  "articles": [
    {
      "title": "Dominant contribution of Asgard archaea to eukaryogenesis",
      "summary": "Nature, Published online: 14 January 2026; doi:10.1038/s41586-025-09960-6A survey of the reconstructed gene set of the last eukaryotic common ancestor shows a consistent link between Asgard archaea and the origin of numerous, functionally diverse eukaryotic genes, demonstrating the dominant Asgard contribution to eukaryogenesis.",
      "content": "Database curation\n\nFor prokaryotes, 75 million sequences were curated from 47,545 fully sequenced prokaryotic genomes obtained from the NCBI GenBank (https://ftp.ncbi.nlm.nih.gov/genomes/) in November 2023 (prok2311) and supplemented with 441,150 proteins sequences from 63 Asgard metagenomes4,5 (prok2311As), selected to represent all clades in these two publications where available. Protein sequences were either taken directly from GenBank annotations or produced by Prodigal v2.6.3 (ref. 75) trained on the set of 12 complete or chromosome-level assembled Asgard genomes. To include only those sequences that are present widely within prokaryotic families, and to minimize the possibility of post-LECA horizontal transfer from eukaryotes, soft-core pangenomes were constructed for each of our 26 curated taxonomic groups, conforming mostly to the NCBI taxonomy rank ‘class’ (see below and Extended Data Fig. 1). To construct the soft-core pangenomes, all sequences from each taxonomic group were clustered individually using mmseqs2 (ref. 37) ‘mmseqs cluster -s 7 -c 0.9 --cov-mode 0’37. All clusters that did not contain sequences from at least 50% of all bacterial species (here defined by lowest rank taxonomic ID within the NCBI taxonomy), or 20% of eukaryotic sequences (see below), were rejected from the database. The effects of alternative pangenome definitions, such as 10%, 25%, 50% and 67% proteins per class, are shown in Extended Data Fig. 1d.\n\nThe eukaryotic database was constructed starting from a curated set of 72 genomes available from the NCBI GenBank. To provide a more accurate representation of eukaryotic diversity, this dataset was supplemented with EukProt v.3 (ref. 36)—a curated database aiming to provide a sparse representation of eukaryotic biology, to create Euk72Ep containing 30.3 million sequences. As sequences included in EukProt v.3 come from a diverse range of sources, some known to contain contaminant prokaryotic sequences, the database was screened for prokaryotic contamination. This screen was carried out by first constructing candidate prokaryotic and eukaryotic HMM databases as described below and querying both databases against the eukaryotic sequence database using hhblits43. All eukaryotic sequences with a top hit alignment score from a prokaryotic HMM were removed from the database before initial clustering.\n\nCuration of taxonomic labels\n\nTo provide a compromise between taxonomic specificity and accuracy of clade assignment, we curated a set of taxonomic labels for both Euk72Ep and Prok2311As to act as representatives. To construct this set, we started by manually assigning all species in EukProt to their closest relatives in the NCBI taxonomy. Then, each species from Prok2311As and Euk72Ep was assigned a taxonomic label corresponding to their ‘Class’ rank (for example, Alphaproteobacteria, Thermococci, Mammalia) based on the NCBI Taxonomy of November 2023 using tools from the ete3 v.3.1.3. toolkit76 as well as custom scripts. For species without a corresponding ‘Class’ rank, the closest relevant rank was assigned manually. This procedure yielded an initial list of 317 unique taxonomic class identifiers. As the rank ‘Class’ does not partition biological diversity evenly, identifiers were further mapped manually to a curated set of 45 eukaryotic and 26 prokaryotic taxonomic superclasses, each present in the NCBI taxonomy (for example, Metazoa, Streptophyta, TACK archaea; Extended Data Fig. 1. Due to the partially unresolved taxonomic relationship within Asgard archaea, all candidate Asgard sequences from Prok2311 or from refs. 6,7 were assigned to the class label ‘Asgard’. Following the recent reclassification of Deltaproteobacteria into Myxococcota, Desulfobacteriota, Bdellovibrionota and SAR324 species that could not be mapped into either of these clades using existing taxonomic annotation were classified as Deltaproteobacteria (0.025% of total data).\n\nSequence clustering and profile database generation\n\nTo transform Euk72Ep and Prok2311As into profile databases suitable for sensitive HMM–HMM searches, we implemented an unsupervised, cascaded sequence-profile clustering pipeline using the tools available in the mmseqs2 software suite37. In brief, each sequence database was initially clustered at 90% sequence identity and 80% pairwise coverage using ‘mmseqs linclust’ and cluster representatives were chosen using ‘mmseqs result2repseq’. This procedure provides a non-redundant set of 6.3 million prokaryotic and 25.1 million eukaryotic sequences for further analysis. The non-redundant sequences are further collapsed into a set of initial profiles and consensus sequence pairs using ‘mmseqs cluster’, ‘mmseqs result2profile’ and ‘mmseqs profile2consensus’. All consensus sequences are queried against their profiles using ‘mmseqs search’ and results clustered using ‘mmseqs clust’. Clusters are mapped to their original non-redundant sequences using ‘mmseqs mergeclusters’ and profiles and consensus sequences are constructed once again. To grow clusters based on their sequence-profile alignments, this procedure of ‘mmseqs profile2consensus - mmseqs search - mmseqs clust - mmseqs result2profile’ is iterated until cluster sizes converge. An 80% pairwise coverage is maintained throughout all steps of the cascaded clustering protocol to avoid homologous overextension. The final clustered databases contain 14.1 million and 91,000 clusters for Euk72Ep and Prok2311As, respectively.\n\nTo transform the unsupervised clusters into a set of HMM profiles, we used a mixed MSA construction strategy coupled with automatic data reduction to create accurate alignments for a wide diversity of cluster sizes and sequence diversities. To construct HMMs, all non-singleton sequence clusters are first aligned using FAMSA v.2.0.1 (ref. 77) to produce an initial alignment. Using the initial alignment, we then reduce the sequence space by calculating an approximate tree using FastTree v.2.1.1. using ‘FastTree -gamma’78, remove long branch outliers as described in ‘EPOC tree construction and processing’ and iteratively removing the closest pairwise leaves using ete3 (ref. 76), keeping the leaf closest to the root, until the desired sequence set size is reached. For profile generation, we retain no more than 300 sequences for both Prok2311As and Euk72Ep. This reduced sequence set is then realigned with muscle5 v.5.1.linux64 (ref. 42) using ‘muscle -diversified’ with five replicates, and the maximum column confidence alignment is extracted using ‘muscle -maxcc’. This alignment is then trimmed to keep columns with more than 0.2 bits of Shannon information defined as the difference of log 2 (20) and the Shannon entropy of the column amino acid distribution. This process of data reduction/alignment/trimming is referred to as ‘prune-and-align’ and used later for downstream analysis. Trimmed alignments are turned into an HMM database using HH-suite with ‘hhconsensus -M 50’, hhmake and ‘cstranslate -f -x 0.3 -c 4 -I a3m’. The final HH-suite databases contained 480,000 and 1.6 million profiles for prokaryotes and eukaryotes, respectively.\n\nCluster annealing\n\nAs the initial mmseqs2 based clustering was carried out in an unsupervised manner, we considered it necessary to ensure that the results were not contingent on our unsupervised partitioning of the data. To this end, a further cluster annealing step was developed which aims to redefine clusters based on the notion of clades as well separated monophyletic groups on phylogenetic trees, rather directly by sequence similarity and coverage. Starting with the existing clustered databases Euk72Ep and Prok2311As, HMM profiles were calculated for each non-singleton cluster and all versus all HMM–HMM searches were performed using HHblits v.3.3.0 (HHblits -n 1 -p 80), retaining hits with at least 80% HHblits probability and 50% pairwise profile coverage. The resulting hits were then clustered using greedy set clustering, as described in mmseqs2, implemented in Python. These superclusters represent our limit of detection for sequence-based methods, but might involve overclustering, possibly merging several similar gene families into one set. To mitigate the potential effect of such overclustering, cluster partitioning was performed based on phylogenetic tree analysis.\n\nTo this end, the supercluster sizes were first reduced using the ‘prune-and-align’ approach described above, after which a master tree was constructed using FastTree -gamma. Given the resulting set of trees, we sought to identify well separated monophyletic sets of leaves, the presence of which would warrant partitioning of the respective superclusters. To perform this tree partitioning in an unsupervised manner, the all-versus-all pairwise leaf distances were calculated as a square distance matrix and embedded into two dimensions using Uniform Manifold Approximation and Projection v.0.5.3 (n_neighbors=50, min_dist=0.3, distance=‘euclidean’)79. This embedding was clustered using HDBSCAN as implemented in scikit-learn v.1.3.0 with default parameters80. We explicitly allow single cluster partitions to ensure that trees with uniform distributions of pairwise branch lengths remain as single clusters. Mapping clusters back to the phylogenetic trees showed that uniform manifold approximation and projection embedded HDBSCAN clusters were well separated in the original trees (Extended Data Fig. 3a). These annealed clades were used in downstream processing, representing a stricter definition of EPOCS than the initial cascaded mmseqs2 clusters. The annealing process redistributed sequences from the 1.6 million eukaryotic clusters into 1.5 million annealed clusters and from 480,000 prokaryotic clusters into 280,000 annealed clusters, highlighting the already dense representation of initial mmseqs2 clusters. Because the embeddings were done per tree, the partitioning into subsets is independent of branch lengths and relies merely on the internal distribution of branch lengths and the sequence diversity within each tree, rather than pre-defined values of tree distances. Thus, well-formed subclades could be identified in sequence sets independent of internal diversity, an essential feature when applying this procedure across our global scope.\n\nSearch for prokaryotic homologues of eukaryotic proteins\n\nGiven that clade-specific protein families were not of direct relevance to this study, we reduced the search space by excluding HMM profiles from eukaryotic clusters with fewer than ten sequences and a lowest common ancestor with a taxonomic rank below ‘Superkingdom’ as calculated by ‘mmseqs lca’. This requires a sequence cluster to contain at least two sequences from different kingdoms, as defined by the NCBI taxonomy (for example, Amoebozoa and Haptista, or Viridiplantae and Opisthokonta), retaining 142,000 profiles of conserved eukaryotic proteins. To associate eukaryotic sequence clusters with homologous prokaryotic clusters, we queried the Euk72Ep HMM database against all Prok2311As HMM profiles using a single iteration of HHBlits v.3.3.0 as ‘HHblits -n 1 -p 80’ and retaining the hits with at least 80% HHblits probability and 80% pairwise profile length. These filters resulted in a total of 20,700 accepted eukaryotic query profiles targeting a total of 8,300 unique prokaryotic profiles. These clusters contained a total of 5.7 million and 1.9 million sequences.\n\nEPOC MSA construction\n\nUnless otherwise stated, all subsequent steps were carried out using custom Python v.3.9 scripts, with taxonomy and tree parsing carried out using ete3 (ref. 76). All sequences from a eukaryotic cluster with at least ten sequences and a lowest common ancestor at the rank of ‘Superkingdom’ (NCBI taxonomy), together with all members of the homologous prokaryotic clusters identified in the HMM–HMM search with at least 80% probability and pairwise sequence coverage, forms an EPOC. As EPOCs varied in size by more than five orders of magnitude (10 to 100,000 sequences), robust data subsampling is necessary for accurate downstream MSA generation and tree construction. We used a variant of the ‘prune-and-align’ strategy described above for profile generation taking into account the taxonomic distribution of the constituent sequences. Rather than iteratively pruning the closest leaves pairwise, we first label each leaf with its corresponding taxonomic label and only prune monophyletic groups, maintaining a count of all pruned leaves per clade. If the procedure fails to reach the target leaf number before converging, all leaves are ordered by the number of pruned relatives and leaves with the lowest number of relatives deleted (retaining the largest monophyletic groups) until the target size is reached. The result approximates a maximum diversity representation, preferentially pruning isolated singleton clades. Using this modified protocol, eukaryotic and prokaryotic sequences are cropped to a maximum of 30 and 70 sequences, respectively. Each EPOC therefore consists of a maximum of 100 representative sequences. All EPOCs are aligned using ‘muscle -diversified’ with five replicates, and the maximum confidence alignment is extracted using the --maxcc argument. This alignment is then trimmed to keep columns with more than 0.15 bits of Shannon information content for tree reconstruction.\n\nEPOC tree construction and processing\n\nFrom the pruned and trimmed alignment, we created a maximum likelihood tree using IQtree2 v.2.3.5. ‘IQtree2 -B 1000 -bnni -m MFP -mset LG,Q.pfam --cmin 4 --cmax 12’ with model parameters estimated by model finder plus46. Candidate models and rate category search ranges were selected based on a test set of 200 randomly chosen EPOCs from the filtered core set analysed with full model parameter evaluation by Model finder46 and ten tree replicates. The LG and Q.pfam models and rate category ranges were chosen as they consistently produced the highest ranking log-likelihoods for a random sample of 200 EPOCs run with full model estimation in IQtree.\n\nAs the master trees are built from sequences obtained through sensitive cascaded sequence-profile clustering, we would in rare cases observe long-stemmed clade outliers in addition to more common long stem leaf outliers. To assess and remove such erroneous data, we first estimated the log-normal distribution of all stem lengths using scipy.stats v.1.11.1 and excluded any stems outside the 0–99.5% probability point function interval. This simultaneously removes long terminal leaf branches as well as highly diverged clades. In rare cases where this pruning would remove either the entire eukaryotic clade or more than 30% of all leaves, the EPOC was discarded (387 EPOCs). The resulting trees were then re-rooted using a weighted midpoint approach so that the sum of all branch stem lengths on either side of the root was equal. For clarity, no trees in our current study have been ‘phylogenetically rooted’ in the biological sense. All references to the ‘root’ refer to the origin of the data structure, not the biological concept.\n\nTo assign taxonomic clades, all leaf nodes were assigned taxonomic labels from our curated set and monophyletic clades were collapsed, taking as the representative the lowest branching leaf. We found that assigning clades purely based on a monophyletic definition of taxonomic purity severely hampered the analysis as leaves can be taxonomically incongruous with their neighbours. This effect most likely stems from cases of locally erroneous tree topology or local HGT, but severely complicates the downstream analysis. We therefore adopted the notion of a ‘soft LCA’ representing the root of a close-to-monophyletic clade. To greedily rank all the best ‘soft LCAs’, for each taxonomic label, the tree was traversed from each monophyletic clade root to the tree root, calculating a score for each internal node:\n\n$$({\\rm{Number}}\\,{\\rm{of}}\\,{\\rm{leaves}}\\,{\\rm{with}}\\,{\\rm{label}}\\,{\\rm{X}}\\,{\\rm{in}}\\,{\\rm{clade}}/{\\rm{clade}}\\,{\\rm{size}})\\times ({\\rm{Number}}\\,{\\rm{of}}\\,{\\rm{leaves}}\\,{\\rm{with}}\\,{\\rm{label}}\\,{\\rm{X}}\\,{\\rm{in}}\\,{\\rm{clade}}/{\\rm{total}}\\,{\\rm{number}}\\,{\\rm{of}}\\,{\\rm{label}}\\,{\\rm{X}})$$\n\nThis metric balances taxonomic ‘purity’ and ‘scope’ for each possible clade of label X. All such nodes are then ordered by this score. Because this score is sensitive to the total number of taxonomic labels in an EPOC, it was not used as a filtering criterion at any point in the analysis, yet is present in the metadata, mentioned here for completeness. To avoid overinterpreting small clades, clades were considered valid if they represented at least three sequences with clade purity more than 0.8 for prokaryotes, and at least five sequences with purity more than 0.8 for eukaryotes. Trees that fail to identify either any eukaryotic or any prokaryotic clades under these constraints, derived primarily from small EPOCs, are discarded (411 EPOCs). Trees with more than three valid eukaryotic clades were considered to show high paraphyly and likewise discarded (781 EPOCs).\n\nEvolutionary hypothesis testing using constraint trees\n\nTo assess the relative probabilities of each sampled prokaryotic clades to represent the eukaryotic sister clade, we used evolutionary hypothesis testing using constraint trees as implemented in IQtree2 (ref. 46). For each EPOC and for each detected eukaryotic clade, we generated a set of constraint trees, one for each possible prokaryotic sister. Each constraint tree had three defined clades enforced throughout tree calculations: (1) the eukaryotic group as defined by all sequences below the eukaryotic LCA, (2) one of the prokaryotic sister groups and (3) all other prokaryotic leaves. We then construct a set of local trees from slices of the original MSA using IQtree2, forcing the constraint tree topology using ‘iqtree2 -g’, using the same evolutionary model as the original, unconstrained ‘master tree’. The set of constrained trees is then ranked using ‘iqtree2 -z’ calculating the relative model assignment confidence for each of the constrained topologies and resulting test metrics are saved for downstream analysis. As the number of trees to evaluate scales by the number of eukaryotic clades multiplied by the number of prokaryotic clades, we limit the sampling to a maximum of three clades per tree for eukaryotes, discarding rare cases of high eukaryotic paraphyly, and only consider the 12 closest prokaryotic clades to each individual eukaryotic clade, based on their topological distance calculated as the number of non-root tree bifurcations from one node to another. The procedure results in an ELW44 for each of the evaluated model trees, here taken as being analogous to model selection confidence that an evaluated prokaryotic clade is the most significant sister to a eukaryotic clade.\n\nEPOC annotation\n\nTo functionally annotate protein families within EPOCs, we generated profiles based on protein sequences in KEGG release v.110 (ref. 45). For each KOG, we extracted KEGG metadata including KEGG pathways and BRITE labels through KEGG’s API. At the time of parsing (January 2024), KEGG contained 26,695 KOGs. Due to KEGG API constraints, protein sequences in KEGG were extracted from Uniprot, first by mapping KEGG proteins to Uniprot IDs using Uniprot’s ID mapping service (https://www.uniprot.org/id-mapping), then by extracting the sequences for these Uniprot IDs corresponding to each KOG81.\n\nFor each KOG, we generated HMM profiles using the prune-and-align pipeline. To increase specificity of labelling, we partitioned those KOGs, which encompass both prokaryotic and eukaryotic sequences, into separate taxonomic groups and sequence alignments were generated separately for prokaryotes and eukaryotes. Each eukaryotic HMM profile forming the basis for a EPOC was queried against our KEGG profile database using ‘HHblits -n 3 -p 80’. Results were subsequently filtered to a pairwise profile coverage of 0.7 using custom scripts. As a result, 12,600 of the 13,500 EPOCs could be annotated by at least one KOG profile at 80% probability and 70% pairwise coverage. The highest probability hits were used for annotation.\n\nData filtering and removal of cases of possible late HGT\n\nUnless otherwise stated, all data are interpreted from the core set of EPOCs meeting the following criteria: (1) the eukaryotic constituent cluster profile identifies at least one target profile in our KEGG profile database at a probability of 80% and 70% coverage; (2) the eukaryotic clades include more than five distinct taxonomic labels, at least one from Amorphea and one from Diaphoretickes, encompassing the LECA and (3) only prokaryotic sister clades with 0.4 < ELW < 0.99 were considered reliable and were included in the analysis. We note the independence on aELW values on the number of eukaryotic clades chosen as a cutoff as shown in Extended Data Fig. 10a. Cases of ELW ≥ 0.99 were not considered as these are found to be disproportionately eukaryotic-like, often branching from within a broader eukaryotic clade, and thus likely derived from late horizontal transfer post LECA. Due to the presence of such high ELW values within alphaproteobacterial associations with Oxidative phosphorylation, in this case, as an exception, ELW values of 1 were included.\n\nTaxonomy remapping and EPOC construction under GTDB taxonomy\n\nTo ensure that the results were robust to taxonomy, the prok2311 database was reformatted under the GTDB taxonomy (v.220) at the level of ‘phyla’49. For taxonomic mapping, first, genomes present in both prok2311 and GTDB were annotated directly with the GTDB taxonomy. For the remaining genomes, taxonomy was assigned through consensus voting by using the set of GTDB marker genes, searching against our data using ‘mmseqs search -s 7 -c 0.5 -e 1e-10’. A phyla level taxonomic label was assigned to each genome based on the largest number of total hits. Genomes without significant hits to GTDB marker genes were discarded for the purpose of this analysis (0.92% of all data). This procedure mapped the prok2311 data to 96 GTDB phyla that were used as taxonomic assignment for EPOC calculations as described above. All additional Asgard data taken from ref. 8 were directly assigned as Asgardarchaeota.\n\nData visualization and plotting\n\nAll plots were prepared using Python v3.9 and pandas v.2.0.3 with Altair v.4.2.2. Layout, annotation and vector editing was done using Inkscape v.1.1.1. All statistical tests were carried out using scipy.stats v.1.11.1.\n\nReporting summary\n\nFurther information on research design is available in the Nature Portfolio Reporting Summary linked to this article.",
      "url": "https://www.nature.com/articles/s41586-025-09960-6",
      "source": "Nature",
      "published": "2026-01-15",
      "sentiment_score": 0.85,
      "reasoning": "The article reports a significant scientific breakthrough in understanding the origin of eukaryotic genes through the dominant contribution of Asgard archaea to eukaryogenesis. This discovery has broad significance for evolutionary biology and our understanding of life’s complexity, representing a major advancement with wide implications for science and education. The article provides substantial methodological detail, demonstrating a focused, well-substantiated research achievement.",
      "category": "Technology",
      "personality_title": "Study reveals Asgard archaea as key contributors to the origin of complex life",
      "personality_presentation": "**Context** – Scientists have long studied how complex life forms, called eukaryotes, first appeared on Earth. Eukaryotes include plants, animals, and fungi. One big question is which simple organisms contributed genes to the earliest eukaryotes.\n\n**What happened** – Researchers analyzed millions of gene sequences from many organisms, focusing especially on a group called Asgard archaea. They compared these genes to those found in early eukaryotes. Their detailed analysis showed that Asgard archaea contributed most of the important genes that helped build the first eukaryotic cells.\n\n**Impact** – This finding is important because it strengthens the idea that Asgard archaea played a dominant role in creating complex life. Understanding this gene contribution helps explain how simple cells evolved into the complex cells that make up plants and animals. It also clarifies a major step in the history of life on Earth.\n\n**What's next step** – Scientists will likely study Asgard archaea more closely to learn how their genes work and how they helped shape early eukaryotes. This could lead to new insights about cell functions and the evolution of life’s complexity.\n\n**One-sentence takeaway** – New research shows that Asgard archaea gave most of the genes needed to build the first complex cells, shedding light on the origin of eukaryotic life.",
      "personality_title_fr": "Une étude révèle que les archées Asgard ont joué un rôle clé dans l'origine de la vie complexe",
      "personality_presentation_fr": "**Contexte** – Les scientifiques cherchent depuis longtemps à comprendre comment les formes de vie complexes, appelées eucaryotes, sont apparues sur Terre. Les eucaryotes comprennent les plantes, les animaux et les champignons. Une grande question est de savoir quels organismes simples ont apporté des gènes aux premiers eucaryotes.\n\n**Ce qui s'est passé** – Des chercheurs ont analysé des millions de séquences génétiques issues de nombreux organismes, en se concentrant particulièrement sur un groupe appelé archées Asgard. Ils ont comparé ces gènes à ceux des premiers eucaryotes. Leur analyse détaillée a montré que les archées Asgard ont fourni la majorité des gènes importants qui ont aidé à construire les premières cellules eucaryotes.\n\n**Impact** – Cette découverte est importante car elle renforce l'idée que les archées Asgard ont joué un rôle dominant dans la création de la vie complexe. Comprendre cette contribution génétique aide à expliquer comment les cellules simples ont évolué vers des cellules complexes qui composent les plantes et les animaux. Cela clarifie aussi une étape majeure dans l'histoire de la vie sur Terre.\n\n**Prochaine étape** – Les scientifiques vont probablement étudier de plus près les archées Asgard pour comprendre comment fonctionnent leurs gènes et comment ils ont aidé à façonner les premiers eucaryotes. Cela pourrait apporter de nouvelles connaissances sur le fonctionnement des cellules et l'évolution de la complexité de la vie.\n\n**Résumé en une phrase** – Une nouvelle recherche montre que les archées Asgard ont fourni la plupart des gènes nécessaires à la construction des premières cellules complexes, éclairant l'origine de la vie eucaryote.",
      "personality_title_es": "Estudio revela que las arqueas Asgard son clave en el origen de la vida compleja",
      "personality_presentation_es": "**Contexto** – Los científicos han estudiado durante mucho tiempo cómo aparecieron las formas de vida complejas llamadas eucariotas. Los eucariotas incluyen plantas, animales y hongos. Una gran pregunta es qué organismos simples aportaron genes a los primeros eucariotas.\n\n**Qué pasó** – Investigadores analizaron millones de secuencias genéticas de muchos organismos, enfocándose especialmente en un grupo llamado arqueas Asgard. Compararon estos genes con los de los primeros eucariotas. Su análisis detallado mostró que las arqueas Asgard contribuyeron con la mayoría de los genes importantes que ayudaron a formar las primeras células eucariotas.\n\n**Impacto** – Este hallazgo es importante porque fortalece la idea de que las arqueas Asgard jugaron un papel dominante en la creación de la vida compleja. Entender esta contribución genética ayuda a explicar cómo las células simples evolucionaron hacia células complejas que forman plantas y animales. También aclara un paso importante en la historia de la vida en la Tierra.\n\n**Próximo paso** – Es probable que los científicos estudien más a fondo a las arqueas Asgard para aprender cómo funcionan sus genes y cómo ayudaron a moldear a los primeros eucariotas. Esto podría llevar a nuevos conocimientos sobre funciones celulares y la evolución de la complejidad de la vida.\n\n**Resumen en una frase** – Una nueva investigación muestra que las arqueas Asgard aportaron la mayoría de los genes necesarios para construir las primeras células complejas, aclarando el origen de la vida eucariota.",
      "image_url": "public/images/news_image_Dominant-contribution-of-Asgard-archaea-to-eukaryo.png",
      "image_prompt": "A detailed, warm-toned painting showing an ancient, intricate tree of life with glowing branching filaments symbolizing the Asgard archaea at its core, radiating connections to diverse clusters of abstract, softly colored shapes representing prokaryotic and eukaryotic genomes, all interconnected by delicate, luminous threads that illustrate evolutionary relationships and the genesis of complex life."
    },
    {
      "title": "Exciplex-enabled high-efficiency, fully stretchable OLEDs",
      "summary": "Nature, Published online: 14 January 2026; doi:10.1038/s41586-025-09904-0Fabrication of fully stretchable organic light-emitting diodes incorporating an intrinsically stretchable exciplex-assisted phosphorescent layer along with MXene-contact stretchable electrodes is described, demonstrating high efficiency and mechanical compliance for applications in next-generation wearable and deformable displays.",
      "content": "Author notes\n\nThese authors contributed equally: Huanyu Zhou, Hyun-Wook Kim, Shin Jung Han, Danzhen Zhang\n\nAuthors and Affiliations\n\nDepartment of Materials Science and Engineering, Seoul National University, Seoul, Republic of Korea Huanyu Zhou, Hyun-Wook Kim, Shin Jung Han, Woo Jin Jeong, Joo Sung Kim, Dong-Hyeok Kim, Jinwoo Park, Kyung Yeon Jang, Eojin Yoon, Min-Jun Sung, Hao Chen, Qingsen Zeng, Chan-Yul Park, Kwan-Nyeong Kim & Tae-Woo Lee A.J. Drexel Nanomaterials Institute, Drexel University, Philadelphia, PA, USA Danzhen Zhang, Teng Zhang & Yury Gogotsi Department of Materials Science and Engineering, Drexel University, Philadelphia, PA, USA Danzhen Zhang, Teng Zhang & Yury Gogotsi Key Laboratory of Luminescence and Optical Information, Ministry of Education, School of Physical Science and Engineering, Beijing Jiaotong University, Beijing, People’s Republic of China Haomiao Yu Center for Organic Photonics and Electronics Research (OPERA), Kyushu University, Fukuoka, Japan Youichi Tsuchiya & Chihaya Adachi Department of Applied Chemistry, Kyushu University, Fukuoka, Japan Youichi Tsuchiya & Chihaya Adachi Department of Materials Science and Engineering, University of Tennessee, Knoxville, TN, USA Bin Hu Department of Chemical and Biological Engineering, Korea University, Seoul, Republic of Korea June Huh Department of Integrated Display Engineering, Yonsei University, Seoul, Republic of Korea Seungyeon Cho & Jong Chan Kim Research Center for Materials Analysis, Korea Basic Science Institute, Daejeon, Republic of Korea Hyung Joong Yun Department of Chemistry, Korea University, Seoul, Republic of Korea Amit Kumar Harit & Han Young Woo Department of Chemical Engineering, Inha University, Incheon, Republic of Korea Yooseong Ahn & Hoichang Yang Department of Chemistry, Gyeongsang National University, Jinju, Republic of Korea Landep Ayuningtias & Yun-Hi Kim Research Institute of Molecular Alchemy (RIMA), Gyeongsang National University, Jinju, Republic of Korea Landep Ayuningtias & Yun-Hi Kim Department of Electrical and Electronic Engineering, Yonsei University, Seoul, Republic of Korea Jong Chan Kim Institute of Engineering Research, Research Institute of Advanced Materials, Soft Foundry, Seoul National University, Seoul, Republic of Korea Tae-Woo Lee\n\nContributions\n\nH.Z. and T.-W.L. conceived the overall concept. T.-W.L. supervised the project. H.Z., H.-W.K. and S.J.H. initiated the proof-of-concept experiments of fully stretchable OLED devices. H.Z. and H.-W.K. designed and optimized the fully stretchable OLEDs and fabricated devices for analysis and demonstrations. H.Z. and H.-W.K. conducted most of the data analysis and interpretation. D.Z. and T.Z. synthesized MXene and prepared its colloidal solutions, D.Z. performed in situ UV–Vis absorption spectroscopy and T.Z. conducted temperature-dependent resistance measurements under the supervision of Y.G. W.J.J. fabricated the rigid OLEDs. B.H. conceived the magneto-PL experiments and H.Y. performed the corresponding measurements. Y.T. conducted temperature-dependent streak camera measurements under the guidance of C.A. J.H. performed MD simulations. S.C. carried out FIM and spectrally resolved FIM measurements and analysis under the supervision of J.C.K. J.S.K. contributed to transient electroluminescence measurements. D.-H.K. assisted with PLQY and ellipsometry data acquisition. H.J.Y. performed in situ UV photoelectron spectroscopy and X-ray photoelectron spectroscopy measurements. J.P. and E.Y. carried out TRPL data acquisition and K.Y.J. conducted further streak camera measurement. A.K.H. synthesized Crown-CPE under the supervision of H.Y.W. M.-J.S., Y.A. and H. Yang performed grazing incidence X-ray diffraction measurements. H.C. and Q.Z. assisted with UV–Vis and PL measurements. C.-Y.P. performed contact-angle measurements. K.-N.K. contributed to the design of the stretching jig. L.A. synthesized 2PTPS under the guidance of Y.-H.K. H.Z. visualized the data and drafted the initial manuscript and other related documents. T.-W.L. provided substantial revisions. H.-W.K., D.Z. and Y.G. reviewed and edited the manuscript.\n\nCorresponding authors\n\nCorrespondence to Yury Gogotsi or Tae-Woo Lee.",
      "url": "https://www.nature.com/articles/s41586-025-09904-0",
      "source": "Nature",
      "published": "2026-01-15",
      "sentiment_score": 0.85,
      "reasoning": "The article reports a significant technological breakthrough in fabricating fully stretchable OLEDs with high efficiency and mechanical compliance, which has broad implications for next-generation wearable and deformable displays. This advancement has tangible benefits for the general public by enabling more versatile, durable, and comfortable electronic devices, representing a meaningful innovation in display technology.",
      "category": "Technology",
      "personality_title": "Scientists create highly efficient, fully stretchable OLED screens",
      "personality_presentation": "**Context** – OLEDs, or organic light-emitting diodes, are a type of screen technology used in TVs, phones, and wearables. Making these screens stretchable without losing quality has been a challenge.\n\n**What happened** – Researchers from universities in South Korea, the USA, Japan, and China developed a new way to make OLED screens that can stretch and bend easily. They used a special glowing layer called an exciplex-assisted phosphorescent layer and stretchy electrodes made from a material called MXene. Their work was published in the journal Nature in January 2026.\n\n**Impact** – This new OLED technology is both highly efficient and very flexible. That means future devices like smartwatches or fitness bands could be more comfortable to wear and less likely to break when bent. It also opens the door for new types of flexible, wearable screens that were not possible before.\n\n**What's next step** – The research team will likely continue improving the materials and testing the stretchable OLEDs in real-world devices. This could lead to commercial products with screens that stretch, fold, or twist without damage.\n\n**One-sentence takeaway** – A new stretchable OLED screen technology offers better performance and flexibility, paving the way for more durable and comfortable wearable devices.",
      "personality_title_fr": "Des scientifiques créent des écrans OLED entièrement extensibles et très efficaces",
      "personality_presentation_fr": "**Contexte** – Les OLED, ou diodes électroluminescentes organiques, sont une technologie d’écran utilisée dans les téléviseurs, téléphones et objets connectés. Il est difficile de fabriquer ces écrans de manière extensible sans perdre en qualité.\n\n**Ce qui s'est passé** – Des chercheurs de Corée du Sud, des États-Unis, du Japon et de Chine ont développé une nouvelle méthode pour fabriquer des écrans OLED qui peuvent s’étirer et se plier facilement. Ils ont utilisé une couche lumineuse spéciale appelée couche phosphorescente assistée par exciplex et des électrodes extensibles en MXene. Leur travail a été publié dans la revue Nature en janvier 2026.\n\n**Impact** – Cette nouvelle technologie OLED est à la fois très efficace et très flexible. Cela signifie que les futurs appareils comme les montres connectées ou les bracelets de fitness pourraient être plus confortables à porter et moins fragiles lorsqu’ils sont pliés. Cela ouvre aussi la voie à de nouveaux types d’écrans flexibles et portables.\n\n**Prochaine étape** – L’équipe de recherche va probablement continuer à améliorer les matériaux et tester ces écrans OLED extensibles dans des appareils réels. Cela pourrait aboutir à des produits commerciaux avec des écrans capables de s’étirer, se plier ou se tordre sans s’abîmer.\n\n**Résumé en une phrase** – Une nouvelle technologie d’écran OLED extensible offre de meilleures performances et une grande flexibilité, ouvrant la voie à des appareils portables plus durables et confortables.",
      "personality_title_es": "Científicos crean pantallas OLED totalmente estirables y altamente eficientes",
      "personality_presentation_es": "**Contexto** – Los OLED, o diodos orgánicos emisores de luz, son una tecnología de pantalla usada en televisores, teléfonos y dispositivos portátiles. Hacer estas pantallas estirables sin perder calidad ha sido un reto.\n\n**Qué pasó** – Investigadores de Corea del Sur, Estados Unidos, Japón y China desarrollaron una nueva forma de fabricar pantallas OLED que pueden estirarse y doblarse fácilmente. Usaron una capa especial luminiscente llamada capa fosforescente asistida por exciplex y electrodos elásticos hechos de un material llamado MXene. Su trabajo se publicó en la revista Nature en enero de 2026.\n\n**Impacto** – Esta nueva tecnología OLED es muy eficiente y flexible. Esto significa que dispositivos futuros como relojes inteligentes o pulseras de ejercicio podrían ser más cómodos de usar y menos propensos a romperse al doblarse. También abre la puerta a nuevos tipos de pantallas flexibles y portátiles.\n\n**Próximo paso** – El equipo de investigación probablemente seguirá mejorando los materiales y probando las pantallas OLED estirables en dispositivos reales. Esto podría llevar a productos comerciales con pantallas que se estiran, doblan o tuercen sin dañarse.\n\n**Resumen en una frase** – Una nueva tecnología de pantalla OLED estirable ofrece mejor rendimiento y flexibilidad, preparando el camino para dispositivos portátiles más duraderos y cómodos.",
      "image_url": "public/images/news_image_Exciplex-enabled-high-efficiency-fully-stretchable.png",
      "image_prompt": "A detailed, warm-toned painting of a flexible, glowing OLED screen gently bending and stretching like a soft, translucent fabric, illuminated by delicate, flowing light patterns symbolizing exciplex energy transfer, set against a simple, neutral background that highlights the innovation of fully stretchable, high-efficiency organic electronics."
    },
    {
      "title": "Direct observation of the Migdal effect induced by neutron bombardment",
      "summary": "Nature, Published online: 14 January 2026; doi:10.1038/s41586-025-09918-8Direct observation of the Migdal effect in neutron–nucleus collisions is reported, which resolves a long-standing gap in experimental validation.",
      "content": "Theory\n\nFor a gas mixture, the differential cross-section of Migdal effect from neutron–nucleus scattering in the soft limit is given by26,27,57\n\n$$\\frac{{{\\rm{d}}}^{2}\\sigma }{{\\rm{d}}{E}_{{\\rm{R}}}{\\rm{d}}{E}_{{\\rm{e}}}}=\\sum _{i}\\frac{{\\rm{d}}{\\sigma }_{{\\rm{s}}}^{i}}{{\\rm{d}}{E}_{{\\rm{R}}}}\\sum _{n\\kappa }\\frac{{\\rm{d}}{p}_{\\upsilon }^{i}(n\\kappa \\to {E}_{{\\rm{e}}})}{{\\rm{d}}{E}_{{\\rm{e}}}}$$ (2)\n\nwhere the summation over i accounts for each species in the gas mixture. \\({\\sigma }_{{\\rm{s}}}^{i}\\) denotes the scattering cross-section, which includes contributions from elastic (n, n), inelastic (n, n′), fission (n, 2n) and radiative capture (n, γ) processes and can be obtained from the ENDF database ENDF/B-VIII.0 (ref. 58). The term \\({p}_{\\upsilon }^{i}(n\\kappa \\to {E}_{{\\rm{e}}})\\) is the transition probability for ionization of an electron from an initial state nκ to a final state with energy E e . This probability can be obtained from first principles using the Dirac–Hartree–Fock method27,57. As we use a 2.5-MeV D–D neutron beam and require an approximately 50 keV NR threshold in our analysis, the chemical bonds of C–H and C–O (about 10 eV) are easily broken at our recoil energies. Accordingly, it is reasonable to approximately treat the C, H and O as the free atoms in our NR energy regime and calculate the likelihood of electrons from Migdal scattering as the sum of the individual Migdal transition probabilities for C, H and O, respectively. Note that we include all final states with at least one electron above the energy threshold of detector, \\({E}_{{\\rm{e}}}^{\\mathrm{th}}\\). This is particularly relevant as it allows for a precise description of the Migdal effect in the experiment.\n\nTo compare with the elastic scattering cross-section, we calculate the total Migdal cross-section by integrating over the kinematically allowed range of NR energies and the energy spectrum of emitted electrons in equation (2):\n\n$${\\sigma }_{\\text{Migdal}}={\\int }_{\\text{max}[{E}_{{\\rm{R}}}^{\\text{min}},{E}_{{\\rm{R}}}^{{\\rm{th}}}]}^{{E}_{{\\rm{R}}}^{\\text{max}}}{\\int }_{{E}_{{\\rm{e}}}^{{\\rm{th}}}}^{{E}_{{\\rm{e}}}^{\\text{max}}}\\frac{{\\rm{d}}{\\sigma }_{{\\rm{s}}}^{i}}{{\\rm{d}}{E}_{{\\rm{R}}}}\\sum _{n\\kappa }\\frac{{\\rm{d}}{p}_{\\upsilon }^{i}(n\\kappa \\to {E}_{{\\rm{e}}})}{{\\rm{d}}{E}_{{\\rm{e}}}}{{\\rm{d}}E}_{{\\rm{e}}}{{\\rm{d}}E}_{{\\rm{R}}}$$ (3)\n\nwhere \\({E}_{{\\rm{N}}}^{\\max }\\) can be expressed as \\({E}_{{\\rm{R}},{\\rm{m}}{\\rm{a}}{\\rm{x}}}=\\frac{4{m}_{{\\rm{n}}}{m}_{{\\rm{T}}}{E}_{{\\rm{n}}}}{{({m}_{{\\rm{n}}}+{m}_{{\\rm{T}}})}^{2}}\\), where m n is the mass of the incident neutron, m T is the mass of the target nucleus and E n is the kinetic energy of incident neutron. \\({E}_{{\\rm{e}}}^{\\max }=10\\,\\mathrm{keV}\\). \\({E}_{{\\rm{n}}}^{\\mathrm{th}}\\) and \\({E}_{{\\rm{e}}}^{\\mathrm{th}}\\) are the thresholds of detector for nucleus and electron recoils, respectively. The ratio \\(r={\\sigma }_{\\text{Migdal}}/{\\sigma }_{\\text{Elastic}}\\) will offer a direct measure to assess the impact of the Migdal effect in dark matter detection experiments. Extended Data Fig. 1e compares the theoretically calculated Migdal differential probabilities for the gas mixture with the experimentally measured results (more detailed information of the theoretical cross-section calculations can be found in Extended Data Fig. 1 and Supplementary Information Note 1). The integrated theoretical probability in the 5–10 keV range is 3.9 × 10−5, which is consistent with the experimental result of \\({(4.9}_{-1.9}^{+2.6})\\times {10}^{-5}\\) within the margin of error.\n\nDetector assembly\n\nThe detector unit is sealed using brazing and laser welding to ensure high gas tightness and good mechanical properties. The main detector components—ceramics, Kovar alloys, beryllium and lead glass—have a low out-gas rate, which greatly reduces the pollution of other impurities in the gas. To fill the detector with working gas, the detector has a gas pipe that is brazed to the cathode. By using brazing technology, the metal ceramic tube shell is constructed of three layers of ceramic rings and four layers of Kovar alloy rings, with a ceramic ring placed between every two layers of Kovar alloy rings. The ceramic layer is used for insulation and positioning between the Kovar alloy layers. The Kovar alloy rings at both ends of the cermet tube shell are used to seal the connection with the cathode and the base by laser welding. The middle two Kovar alloy rings are used to install the gas microchannel plate (GMCP) as the exit electrode of the GMCP. The GMCP is installed in a cermet tube, and the support ring is extruded to fix the GMCP. The two electrodes of the GMCP are electrically connected by the Kovar alloy on the metal cermet tube. The ceramic pedestal is also composed of ceramic and Kovar alloy. A pixel chip is mounted on the ceramic pedestal and electrically connected to the ceramic pedestal using gold wire. The power supply of the pixel chip and information transmission are realized by 24 pins on the ceramic pedestal. The basic performance of the detector is tested59, the parameters and performance of GMCP are provided60, detailed parameters of the Topmetal-II chip are described52,61 and the electronic information of the detector is given62. The structure of the detector and its geometric parameters are shown in Extended Data Fig. 2a.\n\nElectronic system and data acquisition\n\nThe electronics system is functionally divided into three layers: (1) the front-end electronics readout board, (2) the back-end electronics board and (3) the high-voltage board. The front-end electronics board primarily includes the gas pixel detector (GPD) unit and the GPD data readout circuit. The back-end electronics board comprises the main controller, data and firmware storage, communication interfaces and devices, and an external clock. The high-voltage board consists of the GMCP bottom-surface feedback circuit, voltage divider circuit, high-voltage chip and monitoring circuit.\n\nFront-end board\n\nIt is positioned at the top of the electronics system to host the GPD. The performance metrics of the Topmetal-II can be adjusted by external voltages.\n\nBack-end electronics board\n\nIt is responsible for multi-channel signal processing. The FPGA (field-programmable gate array) is equipped with flash memory, storing multiple files to ensure the system can boot correctly in the event of original file corruption. Backup configuration files are stored at specific addresses to mitigate the risk of system startup failures due to FPGA configuration errors.\n\nHigh-voltage board\n\nIt generates and regulates high voltage. The GMCP bottom surface produces pulse signals on electron arrival, which can serve as GPD trigger signals. These signals are processed through a comparator to enhance energy resolution.\n\nTopmetal-II data processing\n\nDuring detection, the output data from the Topmetal-II is quantized, encoded, compressed and stored in real-time in the embedded Multi-Media Card. The GMCP bottom surface signals, coordinated universal time (UTC), system operational status and monitoring data are stored in the embedded Multi-Media Card with different headers. The scanning frequency of the chip determines the performance metrics of the detector, with pixel switching frequency required to be maintained at the MHz level. Consequently, a data compression scheme has been integrated into the data processing. The detector uses the difference compression method for data compression: the apparent diffusion coefficient (ADC) value of each pixel per frame is stored and compared with the ADC value of the previous frame. If the difference exceeds a preset value, the pixel is identified as a signal pixel and transmitted to the erasure module, thereby achieving data volume compression. The frame refresh time of the Topmetal is 2.59 ms, and the coincidence timing resolution between the GMCP signal and the Topmetal is 262 ns (ref. 63).\n\nDetector calibration\n\nThe energy resolution of the detector is calibrated with a 5.9-keV 55Fe source. Photons emitted by 55Fe pass through a collimator and then through a beryllium window above the detector, generating photoelectrons and depositing energy in the detector. The energy spectrum is fitted using a Gaussian distribution, and the full width at half maximum of resolution at 5.9 keV is obtained to be 26.54% (Extended Data Fig. 2b). Further tests on the detector demonstrate strong linearity in its energy response, and the variation of energy resolution with energy can be described by a relationship proportional to 1/√E (ref. 64).\n\nThe deconvolution method is used to evaluate the position resolution of the detector65. When measuring the position resolution of the detector, the experimental distribution is treated as the convolution of the theoretical distribution with the detector resolution function. In practical terms, a flat and smooth-edged copper plate is positioned directly above the detector. X-rays propagate vertically from the source through both the detector and the copper plate. Consequently, the copper plate obstructs a portion of the X-rays, allowing only half of them to enter the detector. The resulting image obtained by imaging the X-rays with the detector shows only the half irradiated by X-rays. In this scenario, the theoretical distribution can be represented by a Dirac Delta function, whereas the experimental distribution can be expressed as the spatial resolution Gaussian function of the detector. The average σ measured in the X and Y directions is 2.4 pixels (200 μm; Extended Data Fig. 2c).\n\nSimulation\n\nThe software framework Star-XP66, specifically developed for this type of gas detectors, is used to simulate Migdal events. Star-XP is built on the well-established GEANT4 simulation platform, which incorporates high-precision neutron collision data from evaluated databases such as ENSDF and JEFF, with rigorous validation for neutron energies below 20 MeV (ref. 67). In particular, it uses the G4NDL4.6 dataset derived from ENDF, ensuring reliable low-energy neutron simulations. The framework considers various primary effects of charged particle motion and ionization in gas, incorporates electronic logic for digitized outputs consistent with experiments and, based on theoretically calculated Migdal electron spectra, integrates a dedicated Migdal effect generator to investigate event selection algorithms and efficiencies.\n\nA comprehensive detector simulation has been implemented in GEANT4, incorporating all main structural components of the experimental setup, including the gas-sensitive detector, ceramic supports, GMCP glass frame, beryllium window and surrounding lead shielding. The model also contains the liquid scintillator system for monitoring neutron flux and spectrum inside the shielding enclosure. This full-scale implementation enables a realistic treatment of particle transport and interactions, allowing us to rigorously evaluate neutron activation backgrounds and ensuring the reliability of the subsequent physics analyses.\n\nD–D neutron flux and spectrum\n\nThe neutron flux and spectrum of the D–D neutron generator are measured and monitored using a 2″ × 2″ diameter EJ309 liquid scintillator detector. The energy linearity and resolution of the detector are calibrated by fitting the Compton edges and full energy deposition peaks of multiple radioactive gamma sources, and the parameterization is described68,69. The response matrix of the EJ309 liquid scintillator detector is simulated with GEANT4 (ref. 70), incorporating neutron interactions with the liquid scintillator, detector energy linearity and resolution and the neutron response function of the EJ309 liquid scintillator68. Neutron energy deposition is determined by applying pulse shape discrimination techniques68 to distinguish neutron signals from gamma background, leveraging the fact that neutron signals typically exhibit a longer tail in the light emission waveform in liquid scintillator. An iterative unfolding process is used using the response matrix and measured energy spectrum. Various algorithms (GRAVEL71 and MLEM72) and initial spectra (Gaussian and uniform) are tested, showing negligible differences in the unfolded neutron spectrum. Statistical uncertainties and the correlation matrix of the unfolded spectrum are obtained using the bootstrap method. The measured neutron spectrum has a peak energy at 2.5 MeV, aligning well with the simulated spectrum73 (Extended Data Fig. 3j). The detailed information on the calibration of EJ309 liquid scintillator, neutron and gamma discrimination measurements, and spectral deconvolution is provided in Extended Data Fig. 3 and Supplementary Information Note 2.\n\nExperimental details\n\nBefore the experiment, measurements of neutrons from the neutron generator and environmental gamma energy spectra are conducted using a liquid scintillator at 87° (Extended Data Fig. 4c,d). During the experiment, neutron beam monitoring is performed in the 0° and 180° directions using liquid scintillators for the D–D neutron generator beam, as shown in Extended Data Fig. 4a.\n\nData acquisition is conducted in two runs: run I in March 2024 and run II in July 2024. In run II, an additional detection unit is added (Extended Data Fig. 4b). Extended Data Fig. 4g,h shows the count rate variations of the Migdal detector and the liquid scintillator detector. The count rate of the liquid scintillator is normalized to the average count rate of the Migdal detector, demonstrating good consistency between the neutron beam and the detector counts. Extended Data Fig. 4e,f shows the variations in the 55Fe gain calibration during the experiment on each day. The pressure and temperature of the detector chamber are continuously monitored during the experiment, and the gas state fluctuations and good airtightness performance during the experiment are shown in Extended Data Fig. 4i–k.\n\nIdentification of NR tracks and ER tracks\n\nInspired by the relevant work of the MIGDAL Collaboration74, YOLOv8 (ref. 75) is applied for ER and NR recognition (training details and model performance are provided in Extended Data Fig. 8 and Supplementary Information Note 4). Considering accuracy and training speed, the YOLOv8m model architecture is the optimal choice for this study. By training, the model architecture can identify tracks in images and provide their classification and positional range information. Data annotation is performed using a platform called Label Studio, in which ERs and NRs are marked in the graphical interface. The training dataset consists of 6,000 experimental data track images and 2,400 simulated data images. For the experimental data images, half feature 55Fe characteristic X-ray photoelectron tracks, and the other half exhibit D–D source experimental NR tracks. For the simulated data images, half include electron tracks of 4–10 keV, and the other half represent NR tracks generated after the interaction of simulated 2.5 MeV neutrons with gas. The validation dataset consists of 3,000 experimental data images and 600 simulated data images, maintaining the same proportions as the training set. By training 200 epochs, the best-performing model achieves an ER identification accuracy of 99.0% and an NR identification accuracy of 99.7%. The model is then used to recognize and retain instances with both ER tracks and NR tracks, in which the distance between track clusters is less than 4 pixels, for further reconstruction and selection.\n\nMigdal event selection algorithm\n\nTo better distinguish between NR and ER tracks for events pre-selected by the YOLO program, the following procedure is implemented. To reconstruct NRs, the average ADC value of the non-zero pixels is calculated, and the pixels with values below the average are excluded. This requirement effectively removes non-NR track from the frame, as the ADC values of the pixels along the NR are significantly higher than those of other signals. The remaining pixels are fitted with a straight line using the least squares method, and the resulting line is designated as the central trajectory of the NR track. The standard deviation \\(\\sigma \\) of the resulting Gaussian distribution, which stands for the diffusion of NR, is then obtained. The two intersection points of the central track line with the image boundaries (x 0 , y 0 ) and (x′ 0 , y′ 0 ) are designated as initial pixel points. The endpoints of the NR track, (x n , y n ) and (x′ n , y′ n ), are iteratively refined using the centre-of-gravity method. Taking (x 0 , y 0 ) as an example, with (x 0 , y 0 ) as the centre and 5σ as the radius, the new centre of gravity (x 1 , y 1 ) is calculated with weighted formula ADC × exp(d/d 0 ), where d is the distance between the pixel and (x 0 , y 0 ) and d 0 is the pixel scale, and the centre-of-gravity method is applied repeatedly within this region until the calculated centre-of-gravity position converges between consecutive iterations.\n\nTo prevent the influence of NR tracks on the reconstruction of ER tracks, morphological erosion processing is applied to the NR track. All pixels with their centres at the midpoint between the two endpoints, at a distance of 4σ from the line, and within a radius of 4σ, are considered as the NR and removed. To ensure the remaining tracks correspond to ER signals, the ER vertex (x e , y e ) is reconstructed for the residual tracks following the methodology described in ref. 76. The distance between the NR and ER is evaluated by\n\n$$R=\\frac{D-4\\sigma }{{L}_{{\\rm{ER}}}}$$ (4)\n\nwhere D is the distance between the reconstructed ER start point and one of the NR endpoints, and L ER stands for the remaining length of ER after NR subtraction. Events with R > 0.5 and ER track length exceeding 5 × 83 µm are discarded, whereas all events with ER track lengths below this threshold are retained. In other words, events are retained if the reconstructed ER vertex lies closer to the NR endpoints along the ER track. To reduce the impact of edge distortion, events are ignored if the edge ADC or edge hit count exceeds 20% of the related summation value. Moreover, events are disregarded if the NR vertex is near the electron track lying within the 3σ range from the edge, or if both ends of the track hit the edge. To minimize accidental coincidences and multi-track backgrounds, events are also disregarded if there are ADC values exceeding 4σ on both sides of the fitted line for the NR. Extended Data Fig. 5 shows the track information of six Migdal candidate events in the experiments.\n\nQuenching effect\n\nThe quenching effect in gases refers to the phenomenon in which the kinetic energy of ions is dissipated through inelastic collisions or excitation processes during their interaction with other molecules77. When ions collide with gas molecules, they transfer energy to the gas molecules, resulting in their excitation or ionization. This energy transfer process is typically inelastic, meaning the kinetic energy of the ions is converted into the internal energy of the gas molecules. In radiation detectors, the quenching effect influences the intensity and characteristics of the detection signals, causing ions with the same kinetic energy to deposit a lower detectable energy in the detector compared with electrons. The ratio between these two energies is defined as the quenching factor. We obtain the quenching factors for the working gas elements from the TRIM78 database, as shown in Extended Data Fig. 6a, and incorporate the corresponding quenching effects into the simulation of NR tracks.\n\nBackground\n\nThe background in the experiment mainly arises from three sources:\n\n1. Secondary effects from neutron recoil processes: these include delta electrons and secondary NR generated during nucleon motion, de-excitation radiation from excited nuclear states and bremsstrahlung radiation from charged particles. 2. Beam-related background: this includes gamma rays produced by non-elastic collisions of neutrons, coincidental gamma rays released during the acceleration process of the neutron generator with recoil nuclei and β decay processes from neutron-activated gas atoms. 3. Environmental background: this includes radioactive elements present in the air and materials, as well as coincidences between delta electrons produced by cosmic muons and recoil nuclei.\n\nFollowing is the detailed discussion of the analysis of specific background components (the results of all backgrounds are shown in Extended Data Table 1).\n\nRecoil-induced δ-ray\n\nThe background of delta electrons is estimated using experimental data. First, delta electrons near the NR tracks are identified and selected. With the requirement that the electron tracks are at least 1 mm away from the vertex, the delta electrons in the middle of the track are obtained. Then, the energy spectrum of the selected delta electrons is plotted and fitted with an exponential function. The expected count of observed δ electrons in the 5–10 keV range is 0.59 ± 0.40 over the entire experimental period. Finally, Monte Carlo methods are used to estimate the relative efficiency ratio of selecting delta electrons at the top and middle of the NR track as 0.060, and the expected background count of δ electrons during the experiment is calculated to be 0.035 ± 0.023.\n\nParticle-induced X-ray emission\n\nTheoretically, the maximum energy of the Auger electrons and photoelectrons of the gas is only 0.5 keV (from oxygen)79, which is barely detectable by the detector within the energy range of 5–10 keV.\n\nBremsstrahlung processes\n\n1. Quasi-free electron bremsstrahlung: in the Coulomb field of the recoiling ion, an electron from the nearby target atoms can be scattered, resulting in the emission of bremsstrahlung radiation80. 2. Secondary electron bremsstrahlung: an electron ejected from the nearby target atoms by the impact of the recoiling ion can interact with other atoms in the target material, leading to the emission of bremsstrahlung radiation81. 3. Atomic bremsstrahlung: the electron bound to the target atoms can be excited to highly bound states or to the continuum due to the impact of the recoiling ion. Subsequently, it can return to the initial state, emitting bremsstrahlung radiation82. If the electron excited to the continuum does not revert to its bound state, a phenomenon known as radiative ionization occurs, also resulting in the emission of bremsstrahlung radiation. In the analysis, the radiative ionization contribution is calculated and considered as part of the overall atomic bremsstrahlung. 4. Nuclear bremsstrahlung: this process arises from the Coulomb scattering interactions between the recoiling ion and the target atoms83.\n\nIn general, the spectra of these four bremsstrahlung processes exhibit a layered structure within the continuum X-ray spectrum. Specifically, the quasi-Free electron bremsstrahlung, secondary electron bremsstrahlung, atomic bremsstrahlung and nuclear bremsstrahlung processes predominate in distinct energy regions of the X-ray spectrum84,85. The theoretical differential cross-sections for the four bremsstrahlung radiation processes induced by protons or light ions with few MeV kinetic energies are described80,82,85,86.\n\nTo estimate the expected number of electrons induced by the four bremsstrahlung processes, the expected number of X-ray emissions and the energy spectrum of X-ray emissions for each type of nucleus are estimated from the differential cross-section of bremsstrahlung. The spectrum is then input into GEANT4 to simulate the photoelectric process. A 200-μm vertex cut for NR and photoelectron is applied, and an energy cut of 5–10 keV is imposed. The resulting background expectation value is calculated to be 10−7, which can be neglected (see Extended Data Fig. 6c–f and Supplementary Information Note 3).\n\nRandom track coincidences\n\nThe random track coincidence is characterized through both data-driven and GEANT4 simulation approaches. In the experiment, the number of photoelectrons, Compton electrons and other possible processes that produce keV-level electrons occurring in the same frame as the NR tracks is estimated. The events with energy deposition in the range of 5–10 keV are selected and represented in a 2D distribution plot of dE/dX compared with circularity. Out of 8.17 × 105 collected events, a total of 63 events are identified as photoelectrons and Compton electrons. The Monte Carlo simulation is then applied to randomly distribute NRs and ERs in the same frame image. Through a selection algorithm, the accidental coincidences are identified as 0.29% of all cases. The expected yield of accidental coincidences in the dataset is then calculated to be 0.180.\n\nComplementing this, full GEANT4 simulations evaluate three background components: (1) single-neutron-induced NR electron pairs; (2) independent neutron interactions producing separate NRs and electrons; and (3) neutron-generated NRs coinciding with gamma-induced electrons. The simulation accounted for all detector components and material interactions, with electrons (5–10 keV) and NRs (>35 keVee) selected using identical criteria to the experimental analysis. The simulated electron energy spectra show good agreement with experimental distributions (Extended Data Fig. 6b). The total simulated background of 0.156 events (0.128 single neutron + 0.019 multi-neutron + 0.009 neutron–photon) matches the data-driven estimate within uncertainties, validating our background modelling framework.\n\nNeutron activation\n\nGEANT4 simulations show that the production rates of unstable nuclides 3H and 14C are both less than 0.01 per million NR tracks with the energy greater than 35 keVee. Considering the half-life of 3H (12.32 years) and 14C (5,700 years), the background from neutron activation can be neglected.\n\nTrace contaminants\n\nThe radioisotope content at natural abundances in He-DME-based gas mixtures is evaluated, including isotopes of 1H, 4He, 12C and 16O, as well as trace radionuclides such as 222Rn, 85Kr, 39Ar and 210Pb. Among the radioactive isotopes of 1H, 4He, 12C and 16O, 3H and 14C contribute almost all electrons by beta decay, with their activities in the detector being (6.38 ± 6.38) × 10−8 Bq and (4.58 ± 4.58) × 10−5 Bq, respectively. Other trace radioactive elements generate an average of (7.25 ± 0.94) × 10−7 electrons per second with energies ranging from 5 to 10 keV. The probability that these electrons have a vertex distance less than 200 μm from ions is 0.00339. Therefore, the estimated value of the trace contaminants background, normalized to the number of experimental data, is 0.00106 ± 0.00087 (see Supplementary Information Note 3, Gas radioactivity).\n\nMuon-induced δ-rays\n\nThe measurement results of the local cosmic muon flux in Lanzhou87 is adopted to estimate the rate of δ-ray production in the detector sensitivity region. Considering the NR rate of D–D neutron source as 1 event per second, the ratio of δ-ray production and NR in the 5–10 keV energy region, accounting for the detector energy resolution, is 1.85 × 10−5. As the locations of δ-ray production and NR are both evenly distributed, their positions are randomly sampled in the detector sensitivity region based on their production rate, and a vertex distance cut of shorter than 200 μm is applied. The 73% muon exclusive efficiency of the detector is also considered in the calculation. The simulation shows that the δ-rays would contribute 0.013 events, normalized to the number of experimental data.\n\nSecondary NR fork\n\nThe production category, rate and energy spectrum of the primary recoil nucleus are estimated by simulating the interactions of the neutron from D–D source with the DME gas with GEANT4. The primary recoil nuclei are then put into TRIM78 to simulate the following cascade process in the DME gas. The vertex distance between primary recoil and secondary recoil is required to be less than 200 μm, and the energy of secondary recoil nucleus should fall into the region of 5–10 keVee, considering the quenching factor88 of NRs. By applying the cut on the 2D distribution of track deposition energy and track length, it is able to reduce the background yield to below 10−3, while maintaining a signal efficiency of approximately 98%.\n\nUncertainty and significance\n\nBackground error estimation\n\nThe systematic uncertainty of recoil-induced δ-ray mainly comes from the YOLO model. The difference in the estimated yields between the two models (YOLOv8m and YOLOv8n) with different model sizes is considered as the systematic uncertainty of this background. For the systematic uncertainty of random track coincidences, both the error in the circularity and dE/dX discrimination of electrons, as well as a 10% variation in the wobble discrimination parameter, and the difference in the background yields with different YOLO models, are considered to estimate the uncertainty. The main contributors to trace contaminants of radionuclides are 3H, 14C and 222Rn. As we have used gas sealed for over a year, the gas radioactivity should be significantly lower than the atmospheric average level. The systematic uncertainty of muon-induced δ-rays consists of the uncertainties of muon flux and detection efficiency. According to the measurement results, the impact of muon flux uncertainty can be neglected, whereas the detector energy resolution contributes a systematic error of 3%. The uncertainty of ε ER is taken as the difference between YOLO models. The energy resolution of the NR tracks is extrapolated based on the energy resolution \\(\\propto 1/\\sqrt{{E}_{\\text{deposit}}}\\) as described in ref. 64. The energy resolution affects the counting of events selected above 35 keVee in the NR energy spectrum, and we have taken this effect into account in the systematic error of \\({n}_{\\text{tot}}^{\\text{NR}}\\).\n\nCross-section and significance estimation\n\nThe profile likelihood method is used for significance calculation and Migdal effect probability error calculation. In this method, a probability model that depends on both the parameters of interest \\({\\boldsymbol{\\pi }}=({{\\rm{\\pi }}}_{0},\\ldots ,{{\\rm{\\pi }}}_{k})\\) and additional nuisance parameters \\({\\boldsymbol{\\theta }}=({{\\rm{\\theta }}}_{0},\\ldots ,{{\\rm{\\theta }}}_{l})\\) is used to describe the data. Denoting the density function as \\(f({\\bf{X}}|{\\boldsymbol{\\pi }},{\\boldsymbol{\\theta }})\\), where \\({\\boldsymbol{X}}=({X}_{0},...,{X}_{n})\\) refers to independent observations, the full likelihood function can be expressed as\n\n$$L({\\boldsymbol{\\pi }},{\\boldsymbol{\\theta }}|{\\bf{X}})=f({\\bf{X}}|{\\boldsymbol{\\pi }},{\\boldsymbol{\\theta }})$$ (5)\n\nThe general approach to constructing confidence intervals is to determine a corresponding hypothesis test. Here, the hypothesis test is \\({{\\rm{H}}}_{0}\\,:{\\boldsymbol{\\pi }}={{\\boldsymbol{\\pi }}}_{0}\\) versus \\({{\\rm{H}}}_{{\\rm{a}}}\\,:{\\boldsymbol{\\pi }}\n\ne {{\\boldsymbol{\\pi }}}_{0}\\), and the test can be based on the likelihood ratio test statistic:\n\n$$\\lambda ({{\\boldsymbol{\\pi }}}_{0}|{\\bf{X}})=\\frac{\\sup \\{L({{\\boldsymbol{\\pi }}}_{{\\bf{0}}},{\\boldsymbol{\\theta }}|{\\bf{X}});{\\boldsymbol{\\theta }}\\}}{\\sup \\{L({\\boldsymbol{\\pi }},{\\boldsymbol{\\theta }}|{\\bf{X}});{\\boldsymbol{\\pi }},{\\boldsymbol{\\theta }}\\}}$$ (6)\n\nA standard result in statistics is that −2 log λ converges in distribution to a χ2 distribution89. Therefore, we can determine the confidence level for the hypothesis H a : π ≠ π 0 by comparing the difference between −2 log λ across various intervals and its minimum value, and then referencing the corresponding χ2 confidence intervals.\n\nThe observed counts X in this experiment follow a Poisson distribution: X ~ Pois(μ + b), where μ is the observed signal rate, and b is the observed background rate. The observed background counts Y are characterized by a Gaussian distribution: Y ~ N(b, σ b ). Assuming X and Y to be independent, we have\n\n$$f(x,y|\\mu ,b)=\\frac{{(\\mu +b)}^{x}}{x!}{{\\rm{e}}}^{-(\\mu +b)}\\cdot \\frac{1}{\\sqrt{2{\\rm{\\pi }}}{\\sigma }_{b}}\\exp \\left(-\\frac{{(y-b)}^{2}}{2{\\sigma }_{b}^{2}}\\right)$$ (7)\n\nHere, the hypothesis test is H 0 : μ = 0 versus Ha: μ ≠ 0. This model can be implemented using the model 5 in the TRolke library of CERN ROOT90 to directly compute the profile likelihood function −2 log λ, the results of which are shown in Extended Data Fig. 7a. The minimum of this likelihood function occurs at \\(\\mu \\) = 5.77, and the corresponding 5σ value is greater than 0, providing significant evidence for the existence of the Migdal effect.\n\nFor the estimation of the upper and lower limits of the cross-section probability errors, the profile likelihood method is also used. It is important to note that the calculation of the cross-section probability must account for the signal efficiency. Therefore, the observed counts X in the signal region are modified to X ~ Pois(en + b), where e is the signal selection efficiency and n is the number of Migdal events generated. The background counts Y remain characterized by Y ~ N(b, σ b ). Moreover, the signal efficiency is assumed to follow a Gaussian distribution: Z ~ N(e, σ e ). The profile likelihood function for this model can also be directly computed using model3 in the TRolke library. The resulting likelihood function, along with the positions of the minimum n min and its lower and upper limits n ll and n ul , are shown in Extended Data Fig. 7b. The error propagation is applied as follows:",
      "url": "https://www.nature.com/articles/s41586-025-09918-8",
      "source": "Nature",
      "published": "2026-01-15",
      "sentiment_score": 0.85,
      "reasoning": "The article reports the first direct experimental observation of the Migdal effect induced by neutron bombardment, resolving a long-standing gap in experimental validation. This breakthrough has significant implications for dark matter detection and nuclear physics, offering a new method to detect rare particle interactions with improved sensitivity. The detailed description of the experimental setup, calibration, data acquisition, and analysis demonstrates a substantive and focused scientific achievement with broad relevance to fundamental physics and technology development.",
      "category": "Technology",
      "personality_title": "Scientists directly observe the Migdal effect for the first time using neutron collisions",
      "personality_presentation": "**Context** – The Migdal effect is a rare physical phenomenon where a neutron hitting an atomic nucleus causes electrons to be knocked loose. Although predicted by theory, it had never been directly observed in experiments. This effect is important because it can help scientists detect elusive particles like dark matter.\n\n**What happened** – In early 2026, researchers successfully detected the Migdal effect by bombarding a special gas-filled detector with neutrons produced from a deuterium-deuterium (D-D) neutron generator. They used a highly sensitive gas pixel detector combined with advanced electronics and machine learning to identify tiny signals from electrons and nuclei recoiling after neutron collisions. The experiment involved careful calibration, simulation, and background checks to confirm the results.\n\n**Impact** – This is the first direct experimental proof of the Migdal effect. Confirming it experimentally closes a decades-old gap between theory and observation. It shows that detectors can identify very faint signals caused by rare particle interactions. This finding is especially important for dark matter research, as the Migdal effect could help detect dark matter particles that are otherwise too hard to observe.\n\n**What's next step** – Scientists will use this new knowledge to improve dark matter detectors and other particle physics experiments. The detailed understanding of the Migdal effect will help design better experiments with higher sensitivity to rare events. Further studies may also explore the effect in different materials and conditions to expand its applications.\n\n**One-sentence takeaway** – Researchers have, for the first time, directly observed the Migdal effect by neutron collisions, paving the way for more sensitive detection of rare particle interactions like dark matter.\n",
      "personality_title_fr": "Observation directe pour la première fois de l’effet Migdal grâce à des collisions de neutrons",
      "personality_presentation_fr": "**Contexte** – L’effet Migdal est un phénomène rare où un neutron frappant un noyau atomique provoque le dégagement d’électrons. Bien que prédit par la théorie, il n’avait jamais été observé directement en laboratoire. Cet effet est important car il peut aider à détecter des particules difficiles à observer, comme la matière noire.\n\n**Ce qui s’est passé** – Début 2026, des chercheurs ont réussi à détecter l’effet Migdal en bombardant un détecteur spécial rempli de gaz avec des neutrons produits par un générateur de neutrons deutérium-deutérium (D-D). Ils ont utilisé un détecteur pixelisé très sensible associé à une électronique avancée et à l’apprentissage automatique pour identifier de très faibles signaux provenant d’électrons et de noyaux après les collisions. L’expérience a été soigneusement calibrée et simulée, avec des vérifications précises des bruits de fond.\n\n**Impact** – C’est la première preuve expérimentale directe de l’effet Migdal. Cette confirmation comble une lacune vieille de plusieurs décennies entre théorie et observation. Elle montre que des détecteurs peuvent identifier des signaux très faibles dus à des interactions de particules rares. Cette découverte est particulièrement importante pour la recherche sur la matière noire, car l’effet Migdal pourrait aider à détecter des particules de matière noire autrement invisibles.\n\n**Prochaine étape** – Les scientifiques utiliseront ces nouvelles connaissances pour améliorer les détecteurs de matière noire et d’autres expériences en physique des particules. La meilleure compréhension de l’effet Migdal permettra de concevoir des expériences plus sensibles. D’autres études pourront aussi explorer cet effet dans différents matériaux et conditions.\n\n**Résumé en une phrase** – Des chercheurs ont observé pour la première fois directement l’effet Migdal par collisions de neutrons, ouvrant la voie à la détection plus sensible d’interactions de particules rares comme la matière noire.\n",
      "personality_title_es": "Científicos observan por primera vez el efecto Migdal mediante colisiones de neutrones",
      "personality_presentation_es": "**Contexto** – El efecto Migdal es un fenómeno raro donde un neutrón que choca con un núcleo atómico provoca que se liberen electrones. Aunque está predicho por la teoría, nunca se había observado directamente en experimentos. Este efecto es importante porque puede ayudar a detectar partículas difíciles de observar, como la materia oscura.\n\n**Qué ocurrió** – A principios de 2026, investigadores lograron detectar el efecto Migdal al bombardear un detector especial lleno de gas con neutrones generados por un generador de neutrones de deuterio-deuterio (D-D). Usaron un detector de píxeles de gas muy sensible junto con electrónica avanzada y aprendizaje automático para identificar señales muy pequeñas de electrones y núcleos que rebotaron tras las colisiones. El experimento se calibró cuidadosamente y se realizaron simulaciones y controles de fondo para confirmar los resultados.\n\n**Impacto** – Esta es la primera prueba experimental directa del efecto Migdal. Confirmarlo cierra una brecha de décadas entre teoría y observación. Demuestra que los detectores pueden identificar señales muy débiles causadas por interacciones raras de partículas. Este hallazgo es especialmente importante para la investigación de la materia oscura, ya que el efecto Migdal podría ayudar a detectar partículas de materia oscura que de otro modo serían muy difíciles de observar.\n\n**Próximos pasos** – Los científicos usarán este nuevo conocimiento para mejorar detectores de materia oscura y otros experimentos de física de partículas. La comprensión detallada del efecto Migdal ayudará a diseñar experimentos con mayor sensibilidad para eventos raros. Se podrían realizar más estudios para explorar el efecto en diferentes materiales y condiciones.\n\n**Conclusión en una frase** – Por primera vez, los investigadores observaron directamente el efecto Migdal mediante colisiones de neutrones, abriendo el camino para detectar con mayor sensibilidad interacciones raras de partículas como la materia oscura.\n",
      "image_url": "public/images/news_image_Direct-observation-of-the-Migdal-effect-induced-by.png",
      "image_prompt": "A detailed, warm-toned painting of a glowing, translucent atomic nucleus surrounded by softly shimmering electron orbits, with gentle streams of energetic neutrons represented as flowing light particles softly colliding with the nucleus, set against a calm, abstract background of interwoven gas molecules symbolized by simple, softly colored spheres, evoking a harmonious and precise scientific discovery atmosphere."
    },
    {
      "title": "3D-printed low-voltage-driven ciliary hydrogel microactuators",
      "summary": "Nature, Published online: 14 January 2026; doi:10.1038/s41586-025-09944-63D-printed gel microcilia arrays printed by two-photon polymerization and composed of a soft acrylic acid-co-acrylamide hydrogel with a nanometre-scale network structure are shown to respond to low-voltage electrical stimuli within milliseconds, enabling dynamic individual control and non-reciprocal 3D motion.",
      "content": "Single-layer microelectrodes fabrication\n\nExtended Data Fig. 2 illustrates the fabrication process of single-layer microelectrodes. Below are the step-by-step details:\n\nStep 1. Preparation of the polyimide substrate (Extended Data Fig. 2a). This work uses PI2611 (HD MicroSystems) as the backbone material. PI2611 is poured onto a blank glass substrate and then spin-coated at 1,500 rpm for 30 s. The glass substrate used to hold the printed hydrogel microactuators must have a thickness of less than 300 µm, as this is the working range of the TPP laser. For this purpose, we use a 180-µm-thick glass substrate for hydrogel printing. No specific thickness is required for the glass substrate used for moulded hydrogel fabrication.\n\nStep 2. Curing the PI2611 polyimide substrate (Extended Data Fig. 2b). We place the spin-coated substrate on a hotplate and heat it from room temperature to 150 °C. We hold this temperature for 10 min and then increase it to 200 °C. The temperature ramp rate is 20 °C per minute. This temperature is maintained for 5 h to fully cure the polyimide.\n\nStep 3. Photoresist coating (Extended Data Fig. 2c). We pour the positive photoresist AZ ECI 3012 (MicroChemicals GmbH) onto the polyimide substrate and spin-coat the photoresist for 30 s at 5,000 rpm.\n\nStep 4. Soft baking (Extended Data Fig. 2d). We bake the positive photoresist at 90 °C for 90 s.\n\nStep 5. Ultraviolet exposure (Extended Data Fig. 2e). We expose the substrate for 8 s using the MJB4 mask aligner (SUSS MicroTec). The ultraviolet density of this machine is 14.3 mJ cm−2 and the patterns are defined using a photomask.\n\nStep 6. Post-exposure bake (Extended Data Fig. 2f). We bake the exposed substrate at 110 °C for 90 s.\n\nStep 7. Development (Extended Data Fig. 2g). We develop the substrate in AZ 726 (MicroChemicals GmbH) developer for 60 s to reveal the patterns.\n\nStep 8. Platinum sputtering (Extended Data Fig. 2h). We deposit a 150-nm-thick platinum (Pt) layer onto the substrate using sputtering.\n\nStep 9. Lift-off process (Extended Data Fig. 2i). We dip the substrate in TechniStrip Micro D350 (MicroChemicals GmbH) photoresist stripper to remove unwanted material and obtain the final microelectrode structures.\n\nHydrogel solutions for 3D printing\n\nFour hydrogel precursor solutions are prepared for TPP-based 3D printing. Acrylic acid (AAc, Sigma-Aldrich) and acrylamide (AAm, Sigma-Aldrich) served as monomers, N,N′-methylenebisacrylamide (BIS, Sigma-Aldrich) as the crosslinker and Omnirad 2100 (IGM Resins) as the photoinitiator. Ethylene glycol was used as the base solvent.\n\nThe four solutions differ in the mass fractions of AAc, AAm and the photoinitiator. The molar masses of AAc (72.06 g mol−1) and AAm (71.08 g mol−1) are nearly identical; therefore, maintaining a constant total mass fraction of AAc and AAm effectively corresponds to a constant overall molar concentration of monomers. This ensures that, across all formulations, the total monomer concentration remains comparable when only the relative ratio of AAc to AAm varies.\n\nBecause the printability of the precursor solution depends on the AAc-to-AAm ratio, the photoinitiator fraction is experimentally adjusted to achieve consistent printing quality. For each monomer ratio, several photoinitiator concentrations are tested under identical printing parameters and the optimal concentration is determined as the one that produced structures without overexposure or underexposure. Overexposure and underexposure are defined as follows: when printing a 10-µm feature under identical parameters, a fabricated structure larger than 10 µm is considered overexposed, whereas one smaller than 10 µm is considered underexposed. All mass fractions reported below are calculated with respect to the initial mass of ethylene glycol before the addition of monomers, crosslinker or photoinitiator.\n\nSolution 1: AAc 15 wt%, AAm 60 wt%, BIS 2 wt%, photoinitiator 7.5 wt%.\n\nSolution 2: AAc 30 wt%, AAm 45 wt%, BIS 2 wt%, photoinitiator 18 wt%.\n\nSolution 3: AAc 45 wt%, AAm 30 wt%, BIS 2 wt%, photoinitiator 28 wt%.\n\nSolution 4: AAc 60 wt%, AAm 15 wt%, BIS 2 wt%, photoinitiator 38 wt%.\n\nHydrogel microactuator 3D printing\n\nA commercial TPP system (Photonic Professional GT, Nanoscribe GmbH) is used to fabricate hydrogel microactuators. The printing is performed using a 25× objective lens with an exposure power of 15 mW. The slicing and hatching distances are set to 300 nm and 200 nm, respectively, with a 45° hatching angle between adjacent layers (Extended Data Fig. 3).\n\nWe immerse the printed sample in an ethylene glycol bath to develop the hydrogel microactuator structure. Subsequently, the sample is transferred to a DI water bath for 10 min. We repeat this process three times to fully replace the solvent inside the hydrogel from ethylene glycol to DI water. Afterwards, the aqueous environment can be adjusted for different experiments accordingly.\n\nComparison between the centimetre–millimetre hydrogel and the micrometre hydrogel\n\nIn contrast to the fast bending mechanism of the micrometre hydrogel actuator, the internal ion migration is much slower in previously reported centimetre–millimetre-scale ionic hydrogels not fabricated by TPP49,50. Even at the same electric-field intensity as our gel microcilia system, for example, 10,000 V m−1, the H+ ions and Na+ ions would take 0.3 s and 16.7 s, respectively, to traverse a 1-cm distance, which is a typical thickness of a centimetre-scale hydrogel actuator. This ion migration time is orders of magnitude slower than at the micrometre scale. Moreover, its larger pore size (Extended Data Fig. 1b (i)) and smaller effective EDL surface area reduce ion transport, thereby weakening bending. Finally, achieving such high electric fields in large systems needs impractical voltages (for example, 200 V for 2-cm-spaced electrodes), which can trigger electrolysis and other vigorous electrochemical reactions.\n\nIn fact, the internal ion migration in millimetre-scale hydrogel is trivial compared with ion partitioning at the gel–liquid interface. Therefore, previously reported millimetre-scale hydrogels49,50 operate through mechanisms distinct from those proposed in the present work. They bend by means of bath-induced pH gradients or interfacial osmotic effects, driven by electrolysis or ion partitioning across the gel–solution interface42,43,44. By contrast, micrometre-scale hydrogels depend on internal ion migration and nanometre-scale channels, resulting in opposite bending directions and response times more than two orders of magnitude faster (Extended Data Fig. 5 and Supplementary Videos 6 and 7). For example, in DI water, a millimetre-scale actuator bends towards the anode in about 120 s, whereas a micrometre-scale actuator bends towards the cathode in about 0.2 s (Extended Data Fig. 5a,b). In 0.15380 mol l−1 NaCl, the millimetre-scale actuator bends towards the cathode in about 30 s, whereas the micrometre-scale actuator bends towards the anode in about 0.3 s (Extended Data Fig. 5c,d).\n\nMechanism in DI water\n\nFor the millimetre-scale mechanism in DI water (Extended Data Fig. 5a), under the applied voltage, electrolysis produces H+ near the anode and OH− near the cathode. Because the AAc-co-AAm network is pH-sensitive, acidic conditions convert –COO− to –COOH (reducing repulsion force and causing contraction), whereas alkaline conditions convert –COOH to –COO− (increasing repulsion and causing swelling). The bath-induced pH gradient therefore shrinks the anode-side region and swells the cathode-side region, resulting in bending towards the anode42.\n\nBy contrast, for the micrometre-scale mechanism in DI water (Extended Data Fig. 5b), the micrometre-scale hydrogel bends towards the cathode. Here fixed –COOH groups partially dissociate into –COO− and mobile H+. To maintain electroneutrality, the dissociated H+ ions largely remain confined within the hydrogel. Under an external field, these H+ ions migrate and accumulate on the cathode-facing side, locally lowering pH and inducing network contraction, which bends the hydrogel towards the cathode.\n\nMechanism in 0.15380 mol l−1 NaCl\n\nFor the millimetre-scale mechanism in 0.15380 mol l−1 NaCl (Extended Data Fig. 5c), in a saline environment, the external field drives the migration of all mobile ions in the bath. The fixed negative charges of the hydrogel influence ion partitioning at the gel–solution interface42,43,44,45, producing non-uniform ion concentrations across four regions (gel anode side: region 2; gel cathode side: region 1; solution anode side: region 4; solution cathode side: region 3). According to Flory’s theory51, the local osmotic pressure difference is \\(\\Delta {\\rm{\\pi }}={RT}\\sum _{i}({c}_{i{\\rm{g}}}-{c}_{i{\\rm{s}}})\\), in which Δπ is the pressure difference, c ig is the ion concentration in the hydrogel, c is is the ion concentration in solution, R is the gas constant and T is temperature. Under steady-state conditions, the osmotic pressure difference on the anode side \\(\\Delta {{\\rm{\\pi }}}_{\\text{Anode side}}={RT}\\sum _{i}\\,({c}_{i{\\rm{region}}2}-{c}_{i{\\rm{region}}4})\\) exceeds that on the cathode side \\(\\Delta {{\\rm{\\pi }}}_{\\text{Cathode side}}={RT}\\sum _{i}({c}_{i{\\rm{region}}1}-{c}_{i{\\rm{region}}3})\\). This imbalance causes the anode side to swell more, bending the hydrogel towards the cathode.\n\nAt the microscale, the dominant factor is the ion concentration gradient inside the hydrogel rather than at the interface. The relevant osmotic pressure is \\(\\Delta {{\\rm{\\pi }}}_{\\text{Inside the hydrogel}}=RT\\sum _{i}({c}_{i{\\rm{r}}{\\rm{e}}{\\rm{g}}{\\rm{i}}{\\rm{o}}{\\rm{n}}1}-{c}_{i{\\rm{r}}{\\rm{e}}{\\rm{g}}{\\rm{i}}{\\rm{o}}{\\rm{n}}2})\\), which remains positive, making the cathode side swell more and driving bending towards the anode (Extended Data Fig. 5d).\n\nOsmotic pressure analysis\n\nPreviously reported centimetre-scale and millimetre-scale hydrogel actuators operated in enclosed solution environments, in which the hydrogel was immersed in a bath equipped with two electrodes on the sidewalls44,50,52 (Extended Data Fig. 6a). In such systems, most ions in the bath are consumed in establishing concentration gradients across the hydrogel–solution interfaces, generating osmotic pressure differences that drive the hydrogel to bend towards the cathode42,43,44.\n\nBy contrast, our microscale hydrogel cilia operate within a localized region (200 µm × 200 µm × 90 µm) inside a much larger bath (4 cm × 4 cm × 3 mm) (Extended Data Fig. 6b). The large bath volume serves as an ion reservoir, allowing rapid diffusion of external ions into the actuation region (Extended Data Fig. 6b (ii)) and thereby preventing the formation of substantial ion concentration gradients or osmotic pressure differences across the hydrogel–solution interfaces.\n\nTo further validate this reason, osmotic-pressure simulations are performed under two distinct scenarios. Here osmotic pressure refers to the interfacial osmotic-pressure difference that governs centimetre-scale and millimetre-scale hydrogel actuation (as defined in Extended Data Fig. 5c). Direct comparison between simulations at different physical scales is not meaningful because the results would not be dimensionally consistent. Therefore, both simulations are conducted at the micrometre scale, with the only variable being the presence or absence of ion sources at the boundaries.\n\nCase 1: macroscale actuation mimicked at the microscale (Extended Data Fig. 6c (i)). The simulation domain is a 2D region of 200 µm × 150 µm containing a hydrogel of dimensions 10 µm × 90 µm, reproducing the relative size ratio between the hydrogel and the bath in the centimetre–millimetre-scale experiments. No external ion source is applied, corresponding to the enclosed environment characteristic of macroscale systems.\n\nCase 2: microscale actuation with ion exchange (Extended Data Fig. 6c (ii)). The geometry and parameters are identical to case 1, except that ion-source boundary conditions are imposed on three sides of the simulation domain, allowing continuous ion exchange between the system and the surroundings.\n\nAs shown in Extended Data Fig. 6d, introducing ion sources at the boundaries markedly reduced the osmotic-pressure difference across the hydrogel–solution interface. This result confirms that, compared with the macroscale condition, the osmotic contribution is greatly diminished at the microscale and is no longer the dominant mechanism governing hydrogel actuation.\n\nCoupled electro-chemo-mechanical model\n\nA fully coupled electro-chemo-mechanical model is developed here. The model simultaneously resolves: (1) ionic concentration distribution under an external electric field and the fixed charges of the hydrogel network; (2) the resulting osmotic body forces generated by non-uniform ion distributions; and (3) the gel deformation driven by these body forces. At this stage, the model focuses on explaining the deformation of hydrogels in ionic solutions under external electric fields and does not include fluid–structure interactions between the gel and the surrounding liquid.\n\nIonic concentration distribution\n\nThe Nernst–Planck equation describes the ion concentration in a charged hydrogel network environment:\n\n$${J}_{\\alpha }=-\\,{D}_{\\alpha }{\\rm{\n\nabla }}{c}_{\\alpha }-{z}_{\\alpha }{\\mu }_{\\alpha }{c}_{\\alpha }\n\nabla \\O +{c}_{\\alpha }v$$ (1)\n\nin which J α is the ion flux (mol (m2 s)−1), D α is the diffusion coefficient of ion species α, c α is the concentration of ion species α, z α is the charge number of the ion (valence), μ α is the mobility of the ion, Ø is the electric potential and v is the velocity of the fluid.\n\nThe change in ion concentration c α over time is governed by the continuity equation, which states that the change rate of the ion concentration is equal to the net flux of ions plus any sources or sinks (chemical reactions, for instance). It is expressed as:\n\n$$\\frac{{\\rm{\\partial }}{c}_{\\alpha }}{{\\rm{\\partial }}t}+{\\rm{\n\nabla }}\\cdot {J}_{\\alpha }={r}_{\\alpha }({c}_{\\beta })$$ (2)\n\nin which \\(\\frac{{\\rm{\\partial }}{c}_{\\alpha }}{{\\rm{\\partial }}t}\\) is the ion concentration change rate, ∇·J α represents the net flow of ions into or out of a region and r α (c β ) is a source term representing the creation or consumption of ion α owing to chemical reactions or other processes involving species β.\n\nBy substituting the Nernst–Planck equation (equation (1)) into the continuity equation (equation (2)), we obtain:\n\n$$\\frac{{\\rm{\\partial }}{c}_{\\alpha }}{{\\rm{\\partial }}t}={\\rm{\n\nabla }}\\cdot [{D}_{\\alpha }{\\rm{\n\nabla }}{c}_{\\alpha }+{z}_{\\alpha }{\\mu }_{\\alpha }{c}_{\\alpha }{\\rm{\n\nabla }}\\O -{c}_{\\alpha }v]+{r}_{\\alpha }({c}_{\\beta })$$ (3)\n\nThe Poisson equation relates the electric potential distribution to the charge density in the system. It is given by\n\n$${{\\rm{\n\nabla }}}^{2}\\O =-\\frac{\\rho }{\\in }$$ (4)\n\nin which ρ is the charge density (total charge per unit volume) and ε is the permittivity of the medium, expressed as ε r ε 0 , in which ε 0 is the vacuum permittivity and ε r is the relative permittivity of the medium.\n\nIn this work, the AAc-co-AAm hydrogel network contains –COOH groups, whose ionization equilibrium is influenced by H+ migration. This equilibrium affects the network charge and mobility of other ions. This equilibrium is included in the modelling by\n\n$$\\frac{{C}_{{\\text{R-COO}}^{-}}\\cdot {C}_{{{\\rm{H}}}^{+}}}{{C}_{\\text{R-COOH}}-{C}_{{\\text{R-COO}}^{-}}}={K}_{a}=5.6\\times {10}^{-5}$$ (5)\n\nin which \\({C}_{{\\text{R-COO}}^{-}}\\) is the concentration of the dissociated function group in the hydrogel, \\({C}_{{{\\rm{H}}}^{+}}\\) is the H+ ion concentration in the hydrogel and C R-COOH is the concentration of the carboxyl group in the hydrogel. The value of C R-COOH is obtained from the initial hydrogel solution. Equations (3)–(5) collectively govern the ion concentration distribution.\n\nForces generated by non-uniform ion distributions\n\nThe force induced by ionic distributions can be separated into two contributions. The first contribution comes from the H+ effect (pH-dependent). H+ modulate the dissociation equilibrium of –COO− groups within the hydrogel network. Variations in the fixed –COO− concentration govern network swelling or contraction. The corresponding force can be expressed as:\n\n$${f}_{{\\rm{pH}}}=E(\\,-\\,{\\rm{\n\nabla }}{({FC}}_{{\\text{R-COO}}^{-}}))$$ (6)\n\nin which F is the Faraday constant and E is the local electric field, which can be obtained from\n\n$$E=-\\,{\\rm{\n\nabla }}\\O .$$ (7)\n\nThe second contribution comes from the local pressure difference induced by ion concentration. According to Flory’s theory51, the local pressure relates to the ion concentration:\n\n$${\\rm{\\pi }}={RT}\\sum _{i}{c}_{i}$$ (8)\n\nin which π is the local pressure, c i is the ion concentration, R is the gas constant and T is temperature.\n\nThe force generated by the non-uniform ion concentration can be expressed by the negative gradient of the local pressure as\n\n$$f=-\\,{\\rm{\n\nabla }}{\\rm{\\pi }}=-\\,{\\rm{\n\nabla }}({RT}\\sum _{i}{c}_{i}).$$ (9)\n\nThe local electric potential Ø, function group concentration \\({C}_{{\\text{R-COO}}^{-}}\\) and ion concentration c i can be calculated from equations (3)–(5).\n\nMechanical deformation\n\nThe deformation of the hydrogel was modelled as a nonlinear hyperelastic material considering geometric nonlinearity. To describe its constitutive behaviour, the first-order compressible Ogden model was used. The strain energy density function is expressed as\n\n$$W=\\frac{\\mu }{\\alpha }({\\lambda }_{1}^{\\alpha }+{\\lambda }_{2}^{\\alpha }+{\\lambda }_{3}^{\\alpha }-3)+\\frac{1}{D}{(J-1)}^{2}$$ (10)\n\nin which λ 1 , λ 2 and λ 3 are the principal stretch ratios, J = λ 1 λ 2 λ 3 is the volume ratio, μ and α are material constants and D is a compressibility parameter related to the bulk modulus K = 2/D. The Poisson’s ratio ν = 0.42 is chosen to define the degree of compressibility. The material parameters (μ, α) are determined by fitting the Ogden model to the data obtained from atomic force microscopy tests and are listed in Extended Data Table 2.\n\nPIV analysis\n\nThe 2D in-plane velocity is calculated using the open-source software PIVlab53. Background subtraction is applied to the particle images to enhance image quality. The multipass fast Fourier transform window deformation algorithm is used to improve the accuracy of displacement estimation. The interrogation area is initially set to 64 × 64 pixels with a step size of 32 pixels, corresponding to a 50% overlap between adjacent interrogation windows. In the second pass, the interrogation area is reduced to 32 × 32 pixels with a step size of 16 pixels. For higher precision, sub-pixel displacements are estimated using a Gaussian 2 × 3 point estimator. The PIV flow pattern results are shown in Fig. 4.\n\nIt should be noted that the patterned electrodes on the substrate influence the accuracy of PIV analysis. For cases in Fig. 4a–c, in which the electrode density is relatively low, the PIV results are reliable. For case in Fig. 4d–g, the electrode density is higher and the trajectories of the PIV tracer particles overlap substantially with the underlying electrodes, leading to larger errors in velocity quantification.\n\n2D flow simulations\n\nFor the numerical simulation of the interaction between the cilia array and fluid, we use the hybrid finite difference/finite element immersed boundary method54, implemented in the open-source software IBAMR, a widely tested C++ framework for the immersed boundary method. The immersed boundary formulation of the problem describes the momentum and velocity of the coupled fluid–structure system in Eulerian form, whereas the deformation and elastic response of the immersed structure is in the Lagrangian form. This study uses 2D simulations, as they effectively capture the flow patterns. Let \\({\\bf{x}}=({x}_{1},{x}_{2})\\in \\Omega \\subset {{\\mathbb{R}}}^{2}\\) denote Cartesian physical coordinates, in which Ω represents the physical region that is occupied by the coupled fluid–structure system, let \\({\\bf{X}}=({X}_{1},{X}_{2})\\in W\\subset {{\\mathbb{R}}}^{2}\\) denote Lagrangian material coordinates that are attached to the structure, in which W is the Lagrangian domain, and let χ(X, t) ∈ Ω denote the physical position of material point X at time t. The strong form of the equations of motion is:\n\n$$\\begin{array}{l}\\rho \\frac{{\\rm{D}}u}{{\\rm{D}}t}({\\bf{x}},t)=-\\,{\\rm{\n\nabla }}p({\\bf{x}},t)+\\mu {{\\rm{\n\nabla }}}^{2}{\\bf{u}}({\\bf{x}},t)+{{\\bf{f}}}^{{\\bf{c}}}({\\bf{x}},t)\\\\ {\\rm{\n\nabla }}\\cdot {\\bf{u}}({\\bf{x}},t)=0\\end{array}$$ (11)\n\n$$\\begin{array}{l}\\begin{array}{c}{{\\bf{f}}}^{{\\bf{c}}}({\\bf{x}},t)={\\int }_{U}{{\\rm{\n\nabla }}}_{{\\bf{X}}}\\cdot {{\\mathbb{P}}}^{{\\bf{e}}}({\\bf{X}},t)\\delta ({\\bf{x}}-\\chi ({\\bf{X}},t)){{\\bf{f}}}^{{\\bf{e}}}({\\bf{x}},t){\\rm{d}}{\\bf{X}}\\\\ \\,-{\\int }_{{\\rm{\\partial }}U}{{\\mathbb{P}}}^{{\\bf{e}}}({\\bf{X}},t){\\bf{N}}({\\bf{X}})\\delta ({\\bf{x}}-\\chi ({\\bf{X}},t)){{\\bf{f}}}^{{\\bf{e}}}({\\bf{x}},t){\\rm{d}}{\\bf{X}}\\\\ \\,\\frac{{\\rm{\\partial }}\\chi }{{\\rm{\\partial }}t}({\\bf{X}},t)={\\int }_{\\Omega }{\\bf{u}}({\\bf{x}},t)\\delta ({\\bf{x}}-\\chi ({\\bf{X}},t)){\\rm{d}}{\\bf{X}}\\end{array}\\end{array}$$ (12)\n\nin which ρ is the mass density, u(x, t) is the Eulerian velocity field, μ is the dynamic viscosity, fe(x, t) is the Eulerian elastic force density, \\({{\\mathbb{P}}}^{{\\bf{e}}}({\\bf{X}},t)\\) is the first Piola–Kirchhoff elastic stress tensor, δ(x) is the 2D delta function and N(X) is the normal vector along the fluid–solid interface. In the computations of this study, the physical domain is Ω = [−L, L][−L, L], in which L is 600 μm for simulations corresponding to fluid experiments 1–3 and 400 µm for fluid experiments 4–7. A zero-gradient boundary condition is applied to boundaries. A staggered-grid finite difference scheme is used to discretize the incompressible Navier–Stokes equations in space. The spatial resolution is Δx = L/128 for simulations 1–3 and Δx = L/64 for simulations 4–7. The total number of the Cartesian grid is \\({\\mathcal{O}}({10}^{5})\\). The circular section of the cilia is discretized into a mesh of triangular elements with an average node spacing of ΔX = L/128. Time-stepping is performed using an implicit scheme proposed by Newren et al.55. The time step size is adjusted to satisfy the Courant–Friedrichs–Lewy condition, with a stability number of approximately 0.1.\n\nIn these 2D flow-field simulations, solid spheres with a diameter of 10 µm are used to approximate the hydrogel cilia. Under the prescribed motions, interactions between the sphere edges and the surrounding fluid generated relatively high flow velocities. However, in reality, hydrogel cilia are porous and soft materials and their interaction with the fluid under identical motions does not produce flow velocities of the same magnitude as in the simulations. The primary aim of the simulation is to qualitatively predict flow-field patterns, not to precisely quantify flow velocities, so the simulated flow patterns are shown in this work (Fig. 4a–g (2)).",
      "url": "https://www.nature.com/articles/s41586-025-09944-6",
      "source": "Nature",
      "published": "2026-01-15",
      "sentiment_score": 0.8,
      "reasoning": "The article reports a significant technological breakthrough in 3D-printed hydrogel microactuators that respond rapidly to low-voltage electrical stimuli, enabling precise dynamic control and 3D motion at the microscale. This advancement has broad implications for micro-robotics, biomedical devices, and fluid manipulation technologies, offering tangible benefits beyond a niche audience. The detailed explanation of fabrication, mechanisms, and modeling demonstrates substantial substance and clarity about the innovation and its impact.",
      "category": "Technology",
      "personality_title": "New 3D-printed hydrogel microactuators move quickly with low voltage",
      "personality_presentation": "**Context** – Scientists have been working to create tiny devices that can move when electricity is applied. These devices, called microactuators, are important for small robots and medical tools. Usually, making microactuators that work fast and with low power is very hard.\n\n**What happened** – Researchers developed a new type of tiny gel structures, called hydrogel microcilia, using a special 3D printing method called two-photon polymerization. These microcilia are made of a soft gel that reacts to very low electrical voltages and can move in three dimensions within milliseconds. The team carefully designed and tested different gel mixtures and built tiny electrodes to control the movement precisely.\n\n**Impact** – This is important because these microactuators work much faster and use much less electricity than previous similar devices. Unlike larger gels that take seconds to move and need high voltage, these tiny gels respond in less than a second with small electric signals. This fast and efficient motion at a very small scale can help build better tiny machines and tools, such as miniature robots or devices that control fluids inside the body.\n\n**What's next step** – The researchers plan to explore how these hydrogel microcilia can be used in real applications, like microfluidic devices that guide liquids or tiny robotic arms. They will also improve the design to make the movement even more precise and study how these gels behave in different environments.\n\n**One-sentence takeaway** – Scientists created tiny 3D-printed gels that quickly move using low voltage, opening new possibilities for small-scale machines and medical devices.",
      "personality_title_fr": "Nouveaux microactionneurs hydrogel imprimés en 3D se déplacent rapidement avec une basse tension",
      "personality_presentation_fr": "**Contexte** – Les scientifiques cherchent à fabriquer de minuscules dispositifs capables de bouger lorsqu’on applique de l’électricité. Ces dispositifs, appelés microactionneurs, sont importants pour les petits robots et les outils médicaux. Habituellement, créer des microactionneurs rapides et peu consommateurs d’énergie est très difficile.\n\n**Ce qui s’est passé** – Des chercheurs ont développé un nouveau type de structures en gel très petites, appelées microcilias hydrogel, grâce à une méthode spéciale d’impression 3D appelée polymérisation biphotonique. Ces microcilias sont faits d’un gel souple qui réagit à de très faibles tensions électriques et peut bouger en trois dimensions en quelques millisecondes. L’équipe a soigneusement conçu différentes mixtures de gel et fabriqué de minuscules électrodes pour contrôler précisément le mouvement.\n\n**Impact** – C’est important car ces microactionneurs fonctionnent beaucoup plus vite et consomment beaucoup moins d’électricité que les dispositifs similaires précédents. Contrairement aux gels plus grands qui mettent des secondes à bouger et nécessitent une haute tension, ces gels minuscules réagissent en moins d’une seconde avec de faibles signaux électriques. Ce mouvement rapide et efficace à très petite échelle peut aider à construire de meilleurs petits machines et outils, comme des mini robots ou des dispositifs qui contrôlent les liquides dans le corps.\n\n**Prochaine étape** – Les chercheurs prévoient d’explorer comment ces microcilias hydrogel peuvent être utilisés dans des applications réelles, comme des dispositifs microfluidiques qui guident les liquides ou de minuscules bras robotiques. Ils vont aussi améliorer la conception pour rendre le mouvement encore plus précis et étudier comment ces gels se comportent dans différents environnements.\n\n**Conclusion en une phrase** – Des scientifiques ont créé de minuscules gels imprimés en 3D qui bougent rapidement avec une basse tension, ouvrant de nouvelles possibilités pour les machines et dispositifs médicaux à petite échelle.",
      "personality_title_es": "Nuevos microactuadores de hidrogel impresos en 3D se mueven rápido con bajo voltaje",
      "personality_presentation_es": "**Contexto** – Los científicos han estado trabajando para crear dispositivos muy pequeños que puedan moverse cuando se les aplica electricidad. Estos dispositivos, llamados microactuadores, son importantes para pequeños robots y herramientas médicas. Normalmente, crear microactuadores que funcionen rápido y con poca energía es muy difícil.\n\n**Qué pasó** – Investigadores desarrollaron un nuevo tipo de estructuras diminutas de gel, llamadas microcilios de hidrogel, usando un método especial de impresión 3D llamado polimerización por dos fotones. Estos microcilios están hechos de un gel suave que responde a voltajes eléctricos muy bajos y pueden moverse en tres dimensiones en milisegundos. El equipo diseñó y probó cuidadosamente diferentes mezclas de gel y construyó electrodos muy pequeños para controlar el movimiento con precisión.\n\n**Impacto** – Esto es importante porque estos microactuadores funcionan mucho más rápido y usan mucha menos electricidad que dispositivos similares anteriores. A diferencia de los geles más grandes que tardan segundos en moverse y necesitan alto voltaje, estos geles diminutos responden en menos de un segundo con señales eléctricas bajas. Este movimiento rápido y eficiente a escala muy pequeña puede ayudar a construir mejores máquinas y herramientas pequeñas, como microrobots o dispositivos que controlan líquidos dentro del cuerpo.\n\n**Próximo paso** – Los investigadores planean explorar cómo estos microcilios de hidrogel pueden usarse en aplicaciones reales, como dispositivos microfluídicos que guían líquidos o pequeños brazos robóticos. También mejorarán el diseño para hacer el movimiento aún más preciso y estudiarán cómo se comportan estos geles en diferentes ambientes.\n\n**Conclusión en una frase** – Científicos crearon geles diminutos impresos en 3D que se mueven rápido usando bajo voltaje, abriendo nuevas posibilidades para máquinas y dispositivos médicos a pequeña escala.",
      "image_url": "public/images/news_image_3D-printed-low-voltage-driven-ciliary-hydrogel-mic.png",
      "image_prompt": "A detailed, warm-toned drawing of delicate, translucent micro-scale hydrogel cilia gracefully bending and waving in a softly glowing fluid environment, with fine, intricate patterns symbolizing electric fields and ion flows subtly weaving through and around them, rendered in gentle natural hues of soft blues, pale greens, and warm amber highlights."
    }
  ]
}